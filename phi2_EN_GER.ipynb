{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig, pipeline, logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, Dataset\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"bentrevett/multi30k\"\n",
    "model_id=\"microsoft/phi-2\"\n",
    "output_model=\"phi2-multi30k-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7dc0c774f6b4ed980d2f7004be1648d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct: translate English to German.\n",
      "Input: the guy with the orange hat is staring at something.\n",
      "Output: Der Mann mit der orange Haut ist ganz zurÃ¼ckgehend.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True, device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "# Instruct chat template chat template\n",
    "#inputs = tokenizer(\"Instruct: translate the guy with the orange hat is staring at something to german\\nOutput:\", return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "inputs = tokenizer(\"Instruct: translate English to German.\\nInput: the guy with the orange hat is staring at something.\\nOutput:\", return_tensors=\"pt\", return_attention_mask=False)\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_prompt(question)-> str:\n",
    "    return f\"Instruct: Translate English to German.\\nInput: {question}\\nOutput:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatted_train(question, response):\n",
    "    instruction_key = \"Instruct: Translate English to German.\"\n",
    "    return f\"{instruction_key}\\nInput: {question}\\nOutput: {response}\"\n",
    "\n",
    "def prepare_train_data_multi_30k(data_id):\n",
    "    data = load_dataset(data_id, split=\"train\")\n",
    "    data_df = data.to_pandas()\n",
    "    data_df[\"text\"] = data_df[[\"de\", \"en\"]].apply(lambda x: \"Instruct: Translate English to German\\nInput: \" + x['en'] + \"\\nOutput: \" + x['de'], axis=1)\n",
    "    data = Dataset.from_pandas(data_df)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'de', 'text'],\n",
       "    num_rows: 29000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_train_data_multi_30k(dataset)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_tokenizer(mode_id):\n",
    "    # use tokenizer from llama2\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # uses bits and bytes package\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=\"float16\", bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "    # loads the model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        mode_id, quantization_config=bnb_config, device_map=\"auto\"\n",
    "    )\n",
    "    model.config.use_cache=False\n",
    "    model.config.pretraining_tp=1\n",
    "    # returns a model and tokenizer\n",
    "    return model, tokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c697f4c2d5242dca0c26bdcd3635e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = get_model_and_tokenizer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262364160\n",
      "all model parameters: 1521392640\n",
      "percentage of trainable model parameters: 17.24%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "# setup Lora configurations\n",
    "peft_config = LoraConfig( # we can have different configurations, will test later\n",
    "        r=8, lora_alpha=16, lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\", target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"dense\"],\n",
    "    )\n",
    "# config = LoraConfig(\n",
    "#     r=32, #Rank\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\n",
    "#         'q_proj',\n",
    "#         'k_proj',\n",
    "#         'v_proj',\n",
    "#         'dense'\n",
    "#     ],\n",
    "#     bias=\"none\",\n",
    "#     lora_dropout=0.05,  # Conventional\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "# )\n",
    "\n",
    "# # 1 - Enabling gradient checkpointing to reduce memory usage during fine-tuning\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# # 2 - Using the prepare_model_for_kbit_training method from PEFT\n",
    "# original_model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# peft_model = get_peft_model(original_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'de', 'text'],\n",
       "    num_rows: 29000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93edc0c822764672b3ad6d91ae807588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = 'phi2-multi30k-en-ger-v1'\n",
    "import transformers\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "        warmup_steps=1,\n",
    "        output_dir=output_model,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        learning_rate=2e-4,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=10,\n",
    "        num_train_epochs=1,\n",
    "        fp16=True,\n",
    "        # push_to_hub=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=data,\n",
    "        peft_config=peft_config,\n",
    "        dataset_text_field=\"text\",\n",
    "        args=training_arguments,\n",
    "        tokenizer=tokenizer,\n",
    "        packing=False,\n",
    "        max_seq_length=1024,\n",
    "       # data_collator=transformers.DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False), \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m7ammadi21\u001b[0m (\u001b[33m7ammadi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hamad.alhammadi/Desktop/AI702/wandb/run-20240313_150259-oegmhzfc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/7ammadi/huggingface/runs/oegmhzfc' target=\"_blank\">driven-planet-8</a></strong> to <a href='https://wandb.ai/7ammadi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/7ammadi/huggingface' target=\"_blank\">https://wandb.ai/7ammadi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/7ammadi/huggingface/runs/oegmhzfc' target=\"_blank\">https://wandb.ai/7ammadi/huggingface/runs/oegmhzfc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16216ae910624b1da81a9daff6b4647f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0224, 'grad_norm': 1.1438884735107422, 'learning_rate': 0.00019999939897423602, 'epoch': 0.0}\n",
      "{'loss': 2.472, 'grad_norm': 1.9803158044815063, 'learning_rate': 0.00019999695731945193, 'epoch': 0.0}\n",
      "{'loss': 2.0821, 'grad_norm': 2.419009208679199, 'learning_rate': 0.00019999263751736143, 'epoch': 0.0}\n",
      "{'loss': 1.9481, 'grad_norm': 2.2339742183685303, 'learning_rate': 0.000199987143945862, 'epoch': 0.01}\n",
      "{'loss': 1.8691, 'grad_norm': 2.0010619163513184, 'learning_rate': 0.00019997925591656946, 'epoch': 0.01}\n",
      "{'loss': 1.8564, 'grad_norm': 1.61525297164917, 'learning_rate': 0.00019996949007243907, 'epoch': 0.01}\n",
      "{'loss': 1.722, 'grad_norm': 1.5216885805130005, 'learning_rate': 0.00019995784659689338, 'epoch': 0.01}\n",
      "{'loss': 1.6487, 'grad_norm': 1.731565237045288, 'learning_rate': 0.0001999443257086206, 'epoch': 0.01}\n",
      "{'loss': 1.7432, 'grad_norm': 1.5749250650405884, 'learning_rate': 0.0001999289276615707, 'epoch': 0.01}\n",
      "{'loss': 1.6853, 'grad_norm': 1.6870571374893188, 'learning_rate': 0.0001999116527449505, 'epoch': 0.01}\n",
      "{'loss': 1.7742, 'grad_norm': 1.4741911888122559, 'learning_rate': 0.00019989250128321824, 'epoch': 0.02}\n",
      "{'loss': 1.7597, 'grad_norm': 1.1067793369293213, 'learning_rate': 0.0001998714736360775, 'epoch': 0.02}\n",
      "{'loss': 1.6551, 'grad_norm': 1.3588634729385376, 'learning_rate': 0.00019984857019847053, 'epoch': 0.02}\n",
      "{'loss': 1.5539, 'grad_norm': 1.501747965812683, 'learning_rate': 0.00019982379140057066, 'epoch': 0.02}\n",
      "{'loss': 1.6268, 'grad_norm': 1.3641808032989502, 'learning_rate': 0.00019979713770777442, 'epoch': 0.02}\n",
      "{'loss': 1.7531, 'grad_norm': 1.5112088918685913, 'learning_rate': 0.00019976860962069265, 'epoch': 0.02}\n",
      "{'loss': 1.5771, 'grad_norm': 1.7500030994415283, 'learning_rate': 0.00019973820767514117, 'epoch': 0.02}\n",
      "{'loss': 1.7277, 'grad_norm': 1.3909748792648315, 'learning_rate': 0.00019970593244213061, 'epoch': 0.02}\n",
      "{'loss': 1.6371, 'grad_norm': 1.5694524049758911, 'learning_rate': 0.00019967178452785585, 'epoch': 0.03}\n",
      "{'loss': 1.5818, 'grad_norm': 1.8502452373504639, 'learning_rate': 0.00019963576457368462, 'epoch': 0.03}\n",
      "{'loss': 1.7246, 'grad_norm': 1.715713620185852, 'learning_rate': 0.00019959787325614522, 'epoch': 0.03}\n",
      "{'loss': 1.7066, 'grad_norm': 1.757887363433838, 'learning_rate': 0.0001995581112869141, 'epoch': 0.03}\n",
      "{'loss': 1.6379, 'grad_norm': 1.8517930507659912, 'learning_rate': 0.00019951647941280235, 'epoch': 0.03}\n",
      "{'loss': 1.6457, 'grad_norm': 1.7594307661056519, 'learning_rate': 0.0001994729784157416, 'epoch': 0.03}\n",
      "{'loss': 1.6333, 'grad_norm': 1.6679879426956177, 'learning_rate': 0.00019942760911276962, 'epoch': 0.03}\n",
      "{'loss': 1.4768, 'grad_norm': 1.9389835596084595, 'learning_rate': 0.00019938037235601463, 'epoch': 0.04}\n",
      "{'loss': 1.6135, 'grad_norm': 1.9944252967834473, 'learning_rate': 0.00019933126903267948, 'epoch': 0.04}\n",
      "{'loss': 1.627, 'grad_norm': 1.8229701519012451, 'learning_rate': 0.000199280300065025, 'epoch': 0.04}\n",
      "{'loss': 1.7059, 'grad_norm': 1.644196629524231, 'learning_rate': 0.00019922746641035265, 'epoch': 0.04}\n",
      "{'loss': 1.5799, 'grad_norm': 2.123877763748169, 'learning_rate': 0.0001991727690609864, 'epoch': 0.04}\n",
      "{'loss': 1.6235, 'grad_norm': 1.521863341331482, 'learning_rate': 0.0001991162090442544, 'epoch': 0.04}\n",
      "{'loss': 1.5641, 'grad_norm': 1.4500981569290161, 'learning_rate': 0.00019905778742246928, 'epoch': 0.04}\n",
      "{'loss': 1.5849, 'grad_norm': 1.7049150466918945, 'learning_rate': 0.00019899750529290866, 'epoch': 0.05}\n",
      "{'loss': 1.5838, 'grad_norm': 1.4427340030670166, 'learning_rate': 0.00019893536378779412, 'epoch': 0.05}\n",
      "{'loss': 1.4843, 'grad_norm': 1.3540406227111816, 'learning_rate': 0.0001988713640742702, 'epoch': 0.05}\n",
      "{'loss': 1.5015, 'grad_norm': 1.6676126718521118, 'learning_rate': 0.00019880550735438236, 'epoch': 0.05}\n",
      "{'loss': 1.5389, 'grad_norm': 1.692915439605713, 'learning_rate': 0.00019873779486505446, 'epoch': 0.05}\n",
      "{'loss': 1.5519, 'grad_norm': 1.5415714979171753, 'learning_rate': 0.00019866822787806547, 'epoch': 0.05}\n",
      "{'loss': 1.5342, 'grad_norm': 1.2953674793243408, 'learning_rate': 0.00019859680770002567, 'epoch': 0.05}\n",
      "{'loss': 1.4398, 'grad_norm': 1.3146231174468994, 'learning_rate': 0.00019852353567235194, 'epoch': 0.06}\n",
      "{'loss': 1.6128, 'grad_norm': 1.6249661445617676, 'learning_rate': 0.0001984484131712429, 'epoch': 0.06}\n",
      "{'loss': 1.5729, 'grad_norm': 1.6739851236343384, 'learning_rate': 0.00019837144160765263, 'epoch': 0.06}\n",
      "{'loss': 1.5333, 'grad_norm': 1.4024118185043335, 'learning_rate': 0.00019829262242726444, 'epoch': 0.06}\n",
      "{'loss': 1.4501, 'grad_norm': 2.7375593185424805, 'learning_rate': 0.00019821195711046375, 'epoch': 0.06}\n",
      "{'loss': 1.3583, 'grad_norm': 1.743599534034729, 'learning_rate': 0.00019812944717231013, 'epoch': 0.06}\n",
      "{'loss': 1.49, 'grad_norm': 1.5152148008346558, 'learning_rate': 0.00019804509416250884, 'epoch': 0.06}\n",
      "{'loss': 1.4583, 'grad_norm': 1.7503583431243896, 'learning_rate': 0.00019795889966538196, 'epoch': 0.06}\n",
      "{'loss': 1.5319, 'grad_norm': 1.3242887258529663, 'learning_rate': 0.00019787086529983832, 'epoch': 0.07}\n",
      "{'loss': 1.4419, 'grad_norm': 1.2472070455551147, 'learning_rate': 0.00019778099271934333, 'epoch': 0.07}\n",
      "{'loss': 1.4459, 'grad_norm': 1.6034499406814575, 'learning_rate': 0.00019768928361188774, 'epoch': 0.07}\n",
      "{'loss': 1.5126, 'grad_norm': 1.6273033618927002, 'learning_rate': 0.00019759573969995616, 'epoch': 0.07}\n",
      "{'loss': 1.5137, 'grad_norm': 1.6401677131652832, 'learning_rate': 0.00019750036274049446, 'epoch': 0.07}\n",
      "{'loss': 1.4426, 'grad_norm': 2.1631698608398438, 'learning_rate': 0.00019740315452487694, 'epoch': 0.07}\n",
      "{'loss': 1.4872, 'grad_norm': 1.6385644674301147, 'learning_rate': 0.0001973041168788727, 'epoch': 0.07}\n",
      "{'loss': 1.519, 'grad_norm': 1.3797874450683594, 'learning_rate': 0.00019720325166261115, 'epoch': 0.08}\n",
      "{'loss': 1.4465, 'grad_norm': 1.6079723834991455, 'learning_rate': 0.00019710056077054731, 'epoch': 0.08}\n",
      "{'loss': 1.4659, 'grad_norm': 1.685526967048645, 'learning_rate': 0.00019699604613142605, 'epoch': 0.08}\n",
      "{'loss': 1.4885, 'grad_norm': 2.136943817138672, 'learning_rate': 0.00019688970970824606, 'epoch': 0.08}\n",
      "{'loss': 1.5051, 'grad_norm': 1.4848560094833374, 'learning_rate': 0.0001967815534982227, 'epoch': 0.08}\n",
      "{'loss': 1.4989, 'grad_norm': 1.8049468994140625, 'learning_rate': 0.00019667157953275072, 'epoch': 0.08}\n",
      "{'loss': 1.3879, 'grad_norm': 1.4930258989334106, 'learning_rate': 0.00019655978987736608, 'epoch': 0.08}\n",
      "{'loss': 1.4798, 'grad_norm': 1.4461944103240967, 'learning_rate': 0.00019644618663170705, 'epoch': 0.09}\n",
      "{'loss': 1.5762, 'grad_norm': 1.9196994304656982, 'learning_rate': 0.00019633077192947483, 'epoch': 0.09}\n",
      "{'loss': 1.5304, 'grad_norm': 1.7173925638198853, 'learning_rate': 0.00019621354793839354, 'epoch': 0.09}\n",
      "{'loss': 1.5234, 'grad_norm': 1.2766408920288086, 'learning_rate': 0.00019609451686016937, 'epoch': 0.09}\n",
      "{'loss': 1.419, 'grad_norm': 1.8307783603668213, 'learning_rate': 0.00019597368093044937, 'epoch': 0.09}\n",
      "{'loss': 1.5494, 'grad_norm': 1.5460002422332764, 'learning_rate': 0.0001958510424187793, 'epoch': 0.09}\n",
      "{'loss': 1.5095, 'grad_norm': 1.3214954137802124, 'learning_rate': 0.0001957266036285612, 'epoch': 0.09}\n",
      "{'loss': 1.5148, 'grad_norm': 1.4552932977676392, 'learning_rate': 0.0001956003668970099, 'epoch': 0.1}\n",
      "{'loss': 1.4416, 'grad_norm': 1.121514081954956, 'learning_rate': 0.0001954723345951094, 'epoch': 0.1}\n",
      "{'loss': 1.4949, 'grad_norm': 1.711046814918518, 'learning_rate': 0.00019534250912756805, 'epoch': 0.1}\n",
      "{'loss': 1.3543, 'grad_norm': 1.6168376207351685, 'learning_rate': 0.00019521089293277356, 'epoch': 0.1}\n",
      "{'loss': 1.3769, 'grad_norm': 1.589281678199768, 'learning_rate': 0.00019507748848274722, 'epoch': 0.1}\n",
      "{'loss': 1.5315, 'grad_norm': 1.7134956121444702, 'learning_rate': 0.00019494229828309726, 'epoch': 0.1}\n",
      "{'loss': 1.4442, 'grad_norm': 1.517888069152832, 'learning_rate': 0.00019480532487297207, 'epoch': 0.1}\n",
      "{'loss': 1.428, 'grad_norm': 1.5975958108901978, 'learning_rate': 0.0001946665708250124, 'epoch': 0.1}\n",
      "{'loss': 1.527, 'grad_norm': 1.4935729503631592, 'learning_rate': 0.00019452603874530285, 'epoch': 0.11}\n",
      "{'loss': 1.426, 'grad_norm': 1.6485792398452759, 'learning_rate': 0.0001943837312733233, 'epoch': 0.11}\n",
      "{'loss': 1.46, 'grad_norm': 1.2314555644989014, 'learning_rate': 0.000194239651081899, 'epoch': 0.11}\n",
      "{'loss': 1.396, 'grad_norm': 1.5743625164031982, 'learning_rate': 0.00019409380087715046, 'epoch': 0.11}\n",
      "{'loss': 1.401, 'grad_norm': 1.3311833143234253, 'learning_rate': 0.0001939461833984428, 'epoch': 0.11}\n",
      "{'loss': 1.3592, 'grad_norm': 1.713042974472046, 'learning_rate': 0.00019379680141833405, 'epoch': 0.11}\n",
      "{'loss': 1.4341, 'grad_norm': 1.7894823551177979, 'learning_rate': 0.0001936456577425232, 'epoch': 0.11}\n",
      "{'loss': 1.59, 'grad_norm': 1.5177555084228516, 'learning_rate': 0.00019349275520979755, 'epoch': 0.12}\n",
      "{'loss': 1.5119, 'grad_norm': 1.6854954957962036, 'learning_rate': 0.0001933380966919792, 'epoch': 0.12}\n",
      "{'loss': 1.5236, 'grad_norm': 1.8884252309799194, 'learning_rate': 0.0001931816850938714, 'epoch': 0.12}\n",
      "{'loss': 1.4102, 'grad_norm': 1.543846845626831, 'learning_rate': 0.0001930235233532037, 'epoch': 0.12}\n",
      "{'loss': 1.4154, 'grad_norm': 1.7884267568588257, 'learning_rate': 0.00019286361444057702, 'epoch': 0.12}\n",
      "{'loss': 1.4937, 'grad_norm': 1.4617282152175903, 'learning_rate': 0.0001927019613594076, 'epoch': 0.12}\n",
      "{'loss': 1.4632, 'grad_norm': 1.6215487718582153, 'learning_rate': 0.00019253856714587084, 'epoch': 0.12}\n",
      "{'loss': 1.4685, 'grad_norm': 1.4614650011062622, 'learning_rate': 0.00019237343486884416, 'epoch': 0.13}\n",
      "{'loss': 1.5805, 'grad_norm': 2.239332437515259, 'learning_rate': 0.00019220656762984932, 'epoch': 0.13}\n",
      "{'loss': 1.3959, 'grad_norm': 1.3089441061019897, 'learning_rate': 0.00019203796856299423, 'epoch': 0.13}\n",
      "{'loss': 1.3198, 'grad_norm': 1.6390149593353271, 'learning_rate': 0.0001918676408349141, 'epoch': 0.13}\n",
      "{'loss': 1.4136, 'grad_norm': 1.5383869409561157, 'learning_rate': 0.00019169558764471192, 'epoch': 0.13}\n",
      "{'loss': 1.3288, 'grad_norm': 1.5866034030914307, 'learning_rate': 0.0001915218122238983, 'epoch': 0.13}\n",
      "{'loss': 1.4397, 'grad_norm': 1.5769267082214355, 'learning_rate': 0.000191346317836331, 'epoch': 0.13}\n",
      "{'loss': 1.4, 'grad_norm': 1.3394813537597656, 'learning_rate': 0.00019116910777815338, 'epoch': 0.14}\n",
      "{'loss': 1.4392, 'grad_norm': 1.7654844522476196, 'learning_rate': 0.00019099018537773268, 'epoch': 0.14}\n",
      "{'loss': 1.4452, 'grad_norm': 1.3701719045639038, 'learning_rate': 0.00019080955399559737, 'epoch': 0.14}\n",
      "{'loss': 1.3738, 'grad_norm': 1.245032548904419, 'learning_rate': 0.00019062721702437413, 'epoch': 0.14}\n",
      "{'loss': 1.3916, 'grad_norm': 1.6898505687713623, 'learning_rate': 0.0001904431778887241, 'epoch': 0.14}\n",
      "{'loss': 1.4658, 'grad_norm': 1.6098896265029907, 'learning_rate': 0.00019025744004527845, 'epoch': 0.14}\n",
      "{'loss': 1.5142, 'grad_norm': 1.688063383102417, 'learning_rate': 0.0001900700069825737, 'epoch': 0.14}\n",
      "{'loss': 1.4671, 'grad_norm': 1.3975298404693604, 'learning_rate': 0.00018988088222098593, 'epoch': 0.14}\n",
      "{'loss': 1.4647, 'grad_norm': 1.4289981126785278, 'learning_rate': 0.00018969006931266486, 'epoch': 0.15}\n",
      "{'loss': 1.3537, 'grad_norm': 1.7299340963363647, 'learning_rate': 0.00018949757184146706, 'epoch': 0.15}\n",
      "{'loss': 1.4471, 'grad_norm': 1.7312699556350708, 'learning_rate': 0.00018930339342288857, 'epoch': 0.15}\n",
      "{'loss': 1.3557, 'grad_norm': 1.2652467489242554, 'learning_rate': 0.0001891075377039971, 'epoch': 0.15}\n",
      "{'loss': 1.3962, 'grad_norm': 1.3246679306030273, 'learning_rate': 0.0001889100083633635, 'epoch': 0.15}\n",
      "{'loss': 1.4856, 'grad_norm': 1.418009638786316, 'learning_rate': 0.00018871080911099264, 'epoch': 0.15}\n",
      "{'loss': 1.3031, 'grad_norm': 1.390013575553894, 'learning_rate': 0.00018850994368825377, 'epoch': 0.15}\n",
      "{'loss': 1.3794, 'grad_norm': 1.4447704553604126, 'learning_rate': 0.00018830741586781016, 'epoch': 0.16}\n",
      "{'loss': 1.3259, 'grad_norm': 1.2049318552017212, 'learning_rate': 0.00018810322945354838, 'epoch': 0.16}\n",
      "{'loss': 1.3947, 'grad_norm': 1.3154560327529907, 'learning_rate': 0.00018789738828050675, 'epoch': 0.16}\n",
      "{'loss': 1.4095, 'grad_norm': 1.3782402276992798, 'learning_rate': 0.00018768989621480338, 'epoch': 0.16}\n",
      "{'loss': 1.4274, 'grad_norm': 1.235505223274231, 'learning_rate': 0.00018748075715356347, 'epoch': 0.16}\n",
      "{'loss': 1.4717, 'grad_norm': 1.47207772731781, 'learning_rate': 0.00018726997502484615, 'epoch': 0.16}\n",
      "{'loss': 1.3915, 'grad_norm': 1.3023332357406616, 'learning_rate': 0.0001870575537875708, 'epoch': 0.16}\n",
      "{'loss': 1.4308, 'grad_norm': 1.4450017213821411, 'learning_rate': 0.00018684349743144254, 'epoch': 0.17}\n",
      "{'loss': 1.5056, 'grad_norm': 1.4237141609191895, 'learning_rate': 0.0001866278099768774, 'epoch': 0.17}\n",
      "{'loss': 1.4641, 'grad_norm': 1.1185321807861328, 'learning_rate': 0.00018641049547492674, 'epoch': 0.17}\n",
      "{'loss': 1.4393, 'grad_norm': 1.3072136640548706, 'learning_rate': 0.00018619155800720123, 'epoch': 0.17}\n",
      "{'loss': 1.418, 'grad_norm': 1.7897858619689941, 'learning_rate': 0.0001859710016857941, 'epoch': 0.17}\n",
      "{'loss': 1.3203, 'grad_norm': 1.5123529434204102, 'learning_rate': 0.00018574883065320408, 'epoch': 0.17}\n",
      "{'loss': 1.4818, 'grad_norm': 1.429192304611206, 'learning_rate': 0.00018552504908225733, 'epoch': 0.17}\n",
      "{'loss': 1.4363, 'grad_norm': 1.840780258178711, 'learning_rate': 0.0001852996611760293, 'epoch': 0.18}\n",
      "{'loss': 1.4778, 'grad_norm': 1.9525278806686401, 'learning_rate': 0.0001850726711677657, 'epoch': 0.18}\n",
      "{'loss': 1.4583, 'grad_norm': 1.7568565607070923, 'learning_rate': 0.00018484408332080296, 'epoch': 0.18}\n",
      "{'loss': 1.4285, 'grad_norm': 1.3324240446090698, 'learning_rate': 0.00018461390192848822, 'epoch': 0.18}\n",
      "{'loss': 1.3024, 'grad_norm': 1.2314724922180176, 'learning_rate': 0.00018438213131409862, 'epoch': 0.18}\n",
      "{'loss': 1.315, 'grad_norm': 1.2703590393066406, 'learning_rate': 0.0001841487758307602, 'epoch': 0.18}\n",
      "{'loss': 1.2952, 'grad_norm': 1.127036213874817, 'learning_rate': 0.000183913839861366, 'epoch': 0.18}\n",
      "{'loss': 1.3056, 'grad_norm': 1.2430466413497925, 'learning_rate': 0.00018367732781849388, 'epoch': 0.18}\n",
      "{'loss': 1.3691, 'grad_norm': 1.4531266689300537, 'learning_rate': 0.00018343924414432358, 'epoch': 0.19}\n",
      "{'loss': 1.3916, 'grad_norm': 1.395196795463562, 'learning_rate': 0.0001831995933105532, 'epoch': 0.19}\n",
      "{'loss': 1.316, 'grad_norm': 1.5030477046966553, 'learning_rate': 0.0001829583798183155, 'epoch': 0.19}\n",
      "{'loss': 1.358, 'grad_norm': 1.3876454830169678, 'learning_rate': 0.00018271560819809292, 'epoch': 0.19}\n",
      "{'loss': 1.4022, 'grad_norm': 1.2055755853652954, 'learning_rate': 0.00018247128300963292, 'epoch': 0.19}\n",
      "{'loss': 1.4525, 'grad_norm': 1.2781192064285278, 'learning_rate': 0.000182225408841862, 'epoch': 0.19}\n",
      "{'loss': 1.3265, 'grad_norm': 1.2875887155532837, 'learning_rate': 0.00018197799031279983, 'epoch': 0.19}\n",
      "{'loss': 1.4131, 'grad_norm': 1.9640483856201172, 'learning_rate': 0.00018172903206947215, 'epoch': 0.2}\n",
      "{'loss': 1.3456, 'grad_norm': 1.7945717573165894, 'learning_rate': 0.00018147853878782382, 'epoch': 0.2}\n",
      "{'loss': 1.1983, 'grad_norm': 1.7589855194091797, 'learning_rate': 0.0001812265151726308, 'epoch': 0.2}\n",
      "{'loss': 1.3822, 'grad_norm': 1.241511583328247, 'learning_rate': 0.00018097296595741188, 'epoch': 0.2}\n",
      "{'loss': 1.4438, 'grad_norm': 1.6051777601242065, 'learning_rate': 0.00018071789590433967, 'epoch': 0.2}\n",
      "{'loss': 1.2908, 'grad_norm': 1.3503636121749878, 'learning_rate': 0.0001804613098041513, 'epoch': 0.2}\n",
      "{'loss': 1.3184, 'grad_norm': 1.4428703784942627, 'learning_rate': 0.00018020321247605832, 'epoch': 0.2}\n",
      "{'loss': 1.357, 'grad_norm': 1.6257495880126953, 'learning_rate': 0.00017994360876765627, 'epoch': 0.21}\n",
      "{'loss': 1.4175, 'grad_norm': 1.3708581924438477, 'learning_rate': 0.00017968250355483354, 'epoch': 0.21}\n",
      "{'loss': 1.4993, 'grad_norm': 1.413565993309021, 'learning_rate': 0.00017941990174167986, 'epoch': 0.21}\n",
      "{'loss': 1.3253, 'grad_norm': 1.190752387046814, 'learning_rate': 0.00017915580826039418, 'epoch': 0.21}\n",
      "{'loss': 1.4054, 'grad_norm': 1.7408783435821533, 'learning_rate': 0.00017889022807119205, 'epoch': 0.21}\n",
      "{'loss': 1.4335, 'grad_norm': 1.5138592720031738, 'learning_rate': 0.00017862316616221237, 'epoch': 0.21}\n",
      "{'loss': 1.3763, 'grad_norm': 1.3900583982467651, 'learning_rate': 0.0001783546275494239, 'epoch': 0.21}\n",
      "{'loss': 1.3732, 'grad_norm': 1.4193649291992188, 'learning_rate': 0.0001780846172765307, 'epoch': 0.22}\n",
      "{'loss': 1.4051, 'grad_norm': 1.3939474821090698, 'learning_rate': 0.00017781314041487786, 'epoch': 0.22}\n",
      "{'loss': 1.4577, 'grad_norm': 1.4329687356948853, 'learning_rate': 0.00017754020206335583, 'epoch': 0.22}\n",
      "{'loss': 1.327, 'grad_norm': 1.4712450504302979, 'learning_rate': 0.0001772658073483049, 'epoch': 0.22}\n",
      "{'loss': 1.4018, 'grad_norm': 1.820670247077942, 'learning_rate': 0.0001769899614234188, 'epoch': 0.22}\n",
      "{'loss': 1.3458, 'grad_norm': 1.4558407068252563, 'learning_rate': 0.000176712669469648, 'epoch': 0.22}\n",
      "{'loss': 1.334, 'grad_norm': 1.2886285781860352, 'learning_rate': 0.00017643393669510235, 'epoch': 0.22}\n",
      "{'loss': 1.3171, 'grad_norm': 1.4023900032043457, 'learning_rate': 0.0001761537683349532, 'epoch': 0.22}\n",
      "{'loss': 1.3841, 'grad_norm': 1.328237533569336, 'learning_rate': 0.00017587216965133518, 'epoch': 0.23}\n",
      "{'loss': 1.335, 'grad_norm': 1.2966368198394775, 'learning_rate': 0.00017558914593324731, 'epoch': 0.23}\n",
      "{'loss': 1.4623, 'grad_norm': 1.5664137601852417, 'learning_rate': 0.00017530470249645368, 'epoch': 0.23}\n",
      "{'loss': 1.1828, 'grad_norm': 1.4137005805969238, 'learning_rate': 0.00017501884468338358, 'epoch': 0.23}\n",
      "{'loss': 1.3919, 'grad_norm': 1.2909668684005737, 'learning_rate': 0.00017473157786303118, 'epoch': 0.23}\n",
      "{'loss': 1.2996, 'grad_norm': 1.1944072246551514, 'learning_rate': 0.0001744429074308547, 'epoch': 0.23}\n",
      "{'loss': 1.3777, 'grad_norm': 1.1377170085906982, 'learning_rate': 0.0001741528388086751, 'epoch': 0.23}\n",
      "{'loss': 1.2948, 'grad_norm': 1.1972368955612183, 'learning_rate': 0.00017386137744457408, 'epoch': 0.24}\n",
      "{'loss': 1.4095, 'grad_norm': 1.377809762954712, 'learning_rate': 0.000173568528812792, 'epoch': 0.24}\n",
      "{'loss': 1.3776, 'grad_norm': 1.8410574197769165, 'learning_rate': 0.00017327429841362493, 'epoch': 0.24}\n",
      "{'loss': 1.3275, 'grad_norm': 1.5436862707138062, 'learning_rate': 0.00017297869177332128, 'epoch': 0.24}\n",
      "{'loss': 1.3568, 'grad_norm': 2.0480728149414062, 'learning_rate': 0.0001726817144439782, 'epoch': 0.24}\n",
      "{'loss': 1.3465, 'grad_norm': 1.5286632776260376, 'learning_rate': 0.00017238337200343708, 'epoch': 0.24}\n",
      "{'loss': 1.3905, 'grad_norm': 2.111313581466675, 'learning_rate': 0.00017208367005517894, 'epoch': 0.24}\n",
      "{'loss': 1.4655, 'grad_norm': 1.5391464233398438, 'learning_rate': 0.0001717826142282191, 'epoch': 0.25}\n",
      "{'loss': 1.2808, 'grad_norm': 1.598191738128662, 'learning_rate': 0.0001714802101770015, 'epoch': 0.25}\n",
      "{'loss': 1.3905, 'grad_norm': 1.4656836986541748, 'learning_rate': 0.00017117646358129256, 'epoch': 0.25}\n",
      "{'loss': 1.3105, 'grad_norm': 1.2405693531036377, 'learning_rate': 0.0001708713801460743, 'epoch': 0.25}\n",
      "{'loss': 1.316, 'grad_norm': 1.4683665037155151, 'learning_rate': 0.00017056496560143746, 'epoch': 0.25}\n",
      "{'loss': 1.3188, 'grad_norm': 1.254947543144226, 'learning_rate': 0.00017025722570247363, 'epoch': 0.25}\n",
      "{'loss': 1.4787, 'grad_norm': 1.3008545637130737, 'learning_rate': 0.00016994816622916724, 'epoch': 0.25}\n",
      "{'loss': 1.2453, 'grad_norm': 1.4131101369857788, 'learning_rate': 0.00016963779298628716, 'epoch': 0.26}\n",
      "{'loss': 1.3304, 'grad_norm': 1.2832989692687988, 'learning_rate': 0.0001693261118032775, 'epoch': 0.26}\n",
      "{'loss': 1.2987, 'grad_norm': 1.3460462093353271, 'learning_rate': 0.00016901312853414798, 'epoch': 0.26}\n",
      "{'loss': 1.3406, 'grad_norm': 20.09526824951172, 'learning_rate': 0.00016869884905736443, 'epoch': 0.26}\n",
      "{'loss': 1.4157, 'grad_norm': 1.4294203519821167, 'learning_rate': 0.00016838327927573798, 'epoch': 0.26}\n",
      "{'loss': 1.3486, 'grad_norm': 1.199905276298523, 'learning_rate': 0.00016806642511631422, 'epoch': 0.26}\n",
      "{'loss': 1.4071, 'grad_norm': 1.586142659187317, 'learning_rate': 0.00016774829253026217, 'epoch': 0.26}\n",
      "{'loss': 1.3222, 'grad_norm': 1.271457552909851, 'learning_rate': 0.00016742888749276223, 'epoch': 0.26}\n",
      "{'loss': 1.2864, 'grad_norm': 1.4852657318115234, 'learning_rate': 0.000167108216002894, 'epoch': 0.27}\n",
      "{'loss': 1.4292, 'grad_norm': 1.5205323696136475, 'learning_rate': 0.0001667862840835237, 'epoch': 0.27}\n",
      "{'loss': 1.2164, 'grad_norm': 1.192945957183838, 'learning_rate': 0.000166463097781191, 'epoch': 0.27}\n",
      "{'loss': 1.3966, 'grad_norm': 1.4102020263671875, 'learning_rate': 0.0001661386631659954, 'epoch': 0.27}\n",
      "{'loss': 1.3534, 'grad_norm': 1.3235472440719604, 'learning_rate': 0.0001658129863314823, 'epoch': 0.27}\n",
      "{'loss': 1.1795, 'grad_norm': 1.3890851736068726, 'learning_rate': 0.00016548607339452853, 'epoch': 0.27}\n",
      "{'loss': 1.3982, 'grad_norm': 1.359186053276062, 'learning_rate': 0.0001651579304952274, 'epoch': 0.27}\n",
      "{'loss': 1.363, 'grad_norm': 1.2406187057495117, 'learning_rate': 0.00016482856379677348, 'epoch': 0.28}\n",
      "{'loss': 1.2955, 'grad_norm': 2.3385584354400635, 'learning_rate': 0.0001644979794853468, 'epoch': 0.28}\n",
      "{'loss': 1.3081, 'grad_norm': 1.5170660018920898, 'learning_rate': 0.00016416618376999655, 'epoch': 0.28}\n",
      "{'loss': 1.2578, 'grad_norm': 1.427870273590088, 'learning_rate': 0.00016383318288252472, 'epoch': 0.28}\n",
      "{'loss': 1.2713, 'grad_norm': 0.985054075717926, 'learning_rate': 0.00016349898307736876, 'epoch': 0.28}\n",
      "{'loss': 1.4454, 'grad_norm': 1.4410243034362793, 'learning_rate': 0.00016316359063148428, 'epoch': 0.28}\n",
      "{'loss': 1.3711, 'grad_norm': 1.142783522605896, 'learning_rate': 0.00016282701184422717, 'epoch': 0.28}\n",
      "{'loss': 1.2474, 'grad_norm': 1.3246253728866577, 'learning_rate': 0.00016248925303723522, 'epoch': 0.29}\n",
      "{'loss': 1.2029, 'grad_norm': 1.1734066009521484, 'learning_rate': 0.00016215032055430934, 'epoch': 0.29}\n",
      "{'loss': 1.3072, 'grad_norm': 1.4064209461212158, 'learning_rate': 0.00016181022076129455, 'epoch': 0.29}\n",
      "{'loss': 1.3683, 'grad_norm': 1.4634994268417358, 'learning_rate': 0.00016146896004596027, 'epoch': 0.29}\n",
      "{'loss': 1.2912, 'grad_norm': 1.3158694505691528, 'learning_rate': 0.00016112654481788055, 'epoch': 0.29}\n",
      "{'loss': 1.2503, 'grad_norm': 1.1770005226135254, 'learning_rate': 0.00016078298150831334, 'epoch': 0.29}\n",
      "{'loss': 1.3845, 'grad_norm': 1.0908687114715576, 'learning_rate': 0.00016043827657008012, 'epoch': 0.29}\n",
      "{'loss': 1.3858, 'grad_norm': 1.4158711433410645, 'learning_rate': 0.00016009243647744433, 'epoch': 0.3}\n",
      "{'loss': 1.3482, 'grad_norm': 1.515255331993103, 'learning_rate': 0.00015974546772599003, 'epoch': 0.3}\n",
      "{'loss': 1.3095, 'grad_norm': 1.4989233016967773, 'learning_rate': 0.00015939737683249975, 'epoch': 0.3}\n",
      "{'loss': 1.4478, 'grad_norm': 1.4482296705245972, 'learning_rate': 0.00015904817033483214, 'epoch': 0.3}\n",
      "{'loss': 1.2181, 'grad_norm': 1.6212176084518433, 'learning_rate': 0.0001586978547917992, 'epoch': 0.3}\n",
      "{'loss': 1.3204, 'grad_norm': 1.08931565284729, 'learning_rate': 0.00015834643678304313, 'epoch': 0.3}\n",
      "{'loss': 1.3989, 'grad_norm': 1.548446774482727, 'learning_rate': 0.0001579939229089125, 'epoch': 0.3}\n",
      "{'loss': 1.2695, 'grad_norm': 1.2248950004577637, 'learning_rate': 0.0001576403197903387, 'epoch': 0.3}\n",
      "{'loss': 1.2784, 'grad_norm': 1.1945050954818726, 'learning_rate': 0.00015728563406871123, 'epoch': 0.31}\n",
      "{'loss': 1.2586, 'grad_norm': 1.4885108470916748, 'learning_rate': 0.00015692987240575304, 'epoch': 0.31}\n",
      "{'loss': 1.3697, 'grad_norm': 1.278096079826355, 'learning_rate': 0.00015657304148339562, 'epoch': 0.31}\n",
      "{'loss': 1.2514, 'grad_norm': 1.534434199333191, 'learning_rate': 0.00015621514800365322, 'epoch': 0.31}\n",
      "{'loss': 1.3878, 'grad_norm': 1.3603787422180176, 'learning_rate': 0.0001558561986884971, 'epoch': 0.31}\n",
      "{'loss': 1.3945, 'grad_norm': 1.6277087926864624, 'learning_rate': 0.0001554962002797293, 'epoch': 0.31}\n",
      "{'loss': 1.315, 'grad_norm': 1.2851710319519043, 'learning_rate': 0.000155135159538856, 'epoch': 0.31}\n",
      "{'loss': 1.3033, 'grad_norm': 1.2988452911376953, 'learning_rate': 0.00015477308324696035, 'epoch': 0.32}\n",
      "{'loss': 1.2001, 'grad_norm': 1.123502254486084, 'learning_rate': 0.00015440997820457555, 'epoch': 0.32}\n",
      "{'loss': 1.3201, 'grad_norm': 1.254187822341919, 'learning_rate': 0.0001540458512315566, 'epoch': 0.32}\n",
      "{'loss': 1.3137, 'grad_norm': 1.5243226289749146, 'learning_rate': 0.00015368070916695254, 'epoch': 0.32}\n",
      "{'loss': 1.1651, 'grad_norm': 1.3973485231399536, 'learning_rate': 0.0001533145588688779, 'epoch': 0.32}\n",
      "{'loss': 1.196, 'grad_norm': 1.2453233003616333, 'learning_rate': 0.00015294740721438386, 'epoch': 0.32}\n",
      "{'loss': 1.3127, 'grad_norm': 1.2874985933303833, 'learning_rate': 0.00015257926109932916, 'epoch': 0.32}\n",
      "{'loss': 1.3655, 'grad_norm': 1.3890708684921265, 'learning_rate': 0.00015221012743825053, 'epoch': 0.33}\n",
      "{'loss': 1.4266, 'grad_norm': 1.5095158815383911, 'learning_rate': 0.0001518400131642329, 'epoch': 0.33}\n",
      "{'loss': 1.3715, 'grad_norm': 1.7133290767669678, 'learning_rate': 0.0001514689252287789, 'epoch': 0.33}\n",
      "{'loss': 1.2545, 'grad_norm': 1.6235318183898926, 'learning_rate': 0.0001510968706016788, 'epoch': 0.33}\n",
      "{'loss': 1.2952, 'grad_norm': 1.504689335823059, 'learning_rate': 0.00015072385627087914, 'epoch': 0.33}\n",
      "{'loss': 1.245, 'grad_norm': 1.2444050312042236, 'learning_rate': 0.0001503498892423517, 'epoch': 0.33}\n",
      "{'loss': 1.3512, 'grad_norm': 1.6536719799041748, 'learning_rate': 0.0001499749765399618, 'epoch': 0.33}\n",
      "{'loss': 1.2914, 'grad_norm': 1.3042089939117432, 'learning_rate': 0.00014959912520533662, 'epoch': 0.34}\n",
      "{'loss': 1.3115, 'grad_norm': 1.4720234870910645, 'learning_rate': 0.00014922234229773257, 'epoch': 0.34}\n",
      "{'loss': 1.3124, 'grad_norm': 1.4465677738189697, 'learning_rate': 0.00014884463489390305, 'epoch': 0.34}\n",
      "{'loss': 1.2599, 'grad_norm': 1.1968400478363037, 'learning_rate': 0.0001484660100879654, 'epoch': 0.34}\n",
      "{'loss': 1.3591, 'grad_norm': 1.27928626537323, 'learning_rate': 0.00014808647499126747, 'epoch': 0.34}\n",
      "{'loss': 1.2481, 'grad_norm': 1.2912497520446777, 'learning_rate': 0.00014770603673225444, 'epoch': 0.34}\n",
      "{'loss': 1.2777, 'grad_norm': 1.4105666875839233, 'learning_rate': 0.00014732470245633464, 'epoch': 0.34}\n",
      "{'loss': 1.4042, 'grad_norm': 1.4427101612091064, 'learning_rate': 0.00014694247932574533, 'epoch': 0.34}\n",
      "{'loss': 1.1944, 'grad_norm': 1.7413733005523682, 'learning_rate': 0.00014655937451941848, 'epoch': 0.35}\n",
      "{'loss': 1.2689, 'grad_norm': 1.0290541648864746, 'learning_rate': 0.00014617539523284554, 'epoch': 0.35}\n",
      "{'loss': 1.3238, 'grad_norm': 1.3495742082595825, 'learning_rate': 0.00014579054867794265, 'epoch': 0.35}\n",
      "{'loss': 1.2062, 'grad_norm': 1.8729292154312134, 'learning_rate': 0.00014540484208291495, 'epoch': 0.35}\n",
      "{'loss': 1.3163, 'grad_norm': 1.087363362312317, 'learning_rate': 0.0001450182826921208, 'epoch': 0.35}\n",
      "{'loss': 1.2771, 'grad_norm': 1.3810474872589111, 'learning_rate': 0.00014463087776593595, 'epoch': 0.35}\n",
      "{'loss': 1.2639, 'grad_norm': 1.3191279172897339, 'learning_rate': 0.000144242634580617, 'epoch': 0.35}\n",
      "{'loss': 1.2758, 'grad_norm': 1.3307445049285889, 'learning_rate': 0.00014385356042816472, 'epoch': 0.36}\n",
      "{'loss': 1.4558, 'grad_norm': 1.2716552019119263, 'learning_rate': 0.00014346366261618716, 'epoch': 0.36}\n",
      "{'loss': 1.3225, 'grad_norm': 1.194375991821289, 'learning_rate': 0.0001430729484677624, 'epoch': 0.36}\n",
      "{'loss': 1.2909, 'grad_norm': 1.3517236709594727, 'learning_rate': 0.00014268142532130102, 'epoch': 0.36}\n",
      "{'loss': 1.2056, 'grad_norm': 1.1840465068817139, 'learning_rate': 0.00014228910053040817, 'epoch': 0.36}\n",
      "{'loss': 1.177, 'grad_norm': 1.4822821617126465, 'learning_rate': 0.0001418959814637455, 'epoch': 0.36}\n",
      "{'loss': 1.2242, 'grad_norm': 1.3433940410614014, 'learning_rate': 0.00014150207550489287, 'epoch': 0.36}\n",
      "{'loss': 1.2911, 'grad_norm': 2.3914637565612793, 'learning_rate': 0.00014110739005220957, 'epoch': 0.37}\n",
      "{'loss': 1.3852, 'grad_norm': 1.345004916191101, 'learning_rate': 0.00014071193251869533, 'epoch': 0.37}\n",
      "{'loss': 1.2976, 'grad_norm': 1.3771675825119019, 'learning_rate': 0.00014031571033185113, 'epoch': 0.37}\n",
      "{'loss': 1.208, 'grad_norm': 1.2799677848815918, 'learning_rate': 0.00013991873093353977, 'epoch': 0.37}\n",
      "{'loss': 1.3067, 'grad_norm': 1.5294452905654907, 'learning_rate': 0.00013952100177984597, 'epoch': 0.37}\n",
      "{'loss': 1.2337, 'grad_norm': 1.176701545715332, 'learning_rate': 0.00013912253034093644, 'epoch': 0.37}\n",
      "{'loss': 1.2455, 'grad_norm': 1.547873854637146, 'learning_rate': 0.00013872332410091946, 'epoch': 0.37}\n",
      "{'loss': 1.2997, 'grad_norm': 1.4097623825073242, 'learning_rate': 0.00013832339055770443, 'epoch': 0.38}\n",
      "{'loss': 1.284, 'grad_norm': 1.181509256362915, 'learning_rate': 0.00013792273722286095, 'epoch': 0.38}\n",
      "{'loss': 1.3494, 'grad_norm': 1.4399925470352173, 'learning_rate': 0.00013752137162147783, 'epoch': 0.38}\n",
      "{'loss': 1.3264, 'grad_norm': 1.2250828742980957, 'learning_rate': 0.00013711930129202163, 'epoch': 0.38}\n",
      "{'loss': 1.2781, 'grad_norm': 1.3807307481765747, 'learning_rate': 0.00013671653378619525, 'epoch': 0.38}\n",
      "{'loss': 1.2588, 'grad_norm': 1.4492745399475098, 'learning_rate': 0.0001363130766687959, 'epoch': 0.38}\n",
      "{'loss': 1.2929, 'grad_norm': 1.4675312042236328, 'learning_rate': 0.0001359089375175731, 'epoch': 0.38}\n",
      "{'loss': 1.3184, 'grad_norm': 1.436928391456604, 'learning_rate': 0.00013550412392308641, 'epoch': 0.38}\n",
      "{'loss': 1.2098, 'grad_norm': 1.1968581676483154, 'learning_rate': 0.00013509864348856275, 'epoch': 0.39}\n",
      "{'loss': 1.2948, 'grad_norm': 1.2623659372329712, 'learning_rate': 0.0001346925038297538, 'epoch': 0.39}\n",
      "{'loss': 1.34, 'grad_norm': 1.3547013998031616, 'learning_rate': 0.00013428571257479265, 'epoch': 0.39}\n",
      "{'loss': 1.2054, 'grad_norm': 1.3376930952072144, 'learning_rate': 0.0001338782773640508, 'epoch': 0.39}\n",
      "{'loss': 1.2231, 'grad_norm': 1.4474573135375977, 'learning_rate': 0.00013347020584999447, 'epoch': 0.39}\n",
      "{'loss': 1.2703, 'grad_norm': 1.6005237102508545, 'learning_rate': 0.00013306150569704106, 'epoch': 0.39}\n",
      "{'loss': 1.1919, 'grad_norm': 1.2843084335327148, 'learning_rate': 0.00013265218458141507, 'epoch': 0.39}\n",
      "{'loss': 1.3082, 'grad_norm': 1.3231219053268433, 'learning_rate': 0.00013224225019100393, 'epoch': 0.4}\n",
      "{'loss': 1.2206, 'grad_norm': 1.4395568370819092, 'learning_rate': 0.0001318317102252135, 'epoch': 0.4}\n",
      "{'loss': 1.3788, 'grad_norm': 1.436942458152771, 'learning_rate': 0.00013142057239482383, 'epoch': 0.4}\n",
      "{'loss': 1.2518, 'grad_norm': 1.302151083946228, 'learning_rate': 0.00013100884442184395, 'epoch': 0.4}\n",
      "{'loss': 1.2657, 'grad_norm': 1.5949128866195679, 'learning_rate': 0.0001305965340393669, 'epoch': 0.4}\n",
      "{'loss': 1.3193, 'grad_norm': 1.366407036781311, 'learning_rate': 0.00013018364899142475, 'epoch': 0.4}\n",
      "{'loss': 1.3214, 'grad_norm': 1.4980525970458984, 'learning_rate': 0.0001297701970328428, 'epoch': 0.4}\n",
      "{'loss': 1.3573, 'grad_norm': 1.270117998123169, 'learning_rate': 0.00012935618592909418, 'epoch': 0.41}\n",
      "{'loss': 1.375, 'grad_norm': 1.6204626560211182, 'learning_rate': 0.00012894162345615387, 'epoch': 0.41}\n",
      "{'loss': 1.2581, 'grad_norm': 1.5320920944213867, 'learning_rate': 0.00012852651740035274, 'epoch': 0.41}\n",
      "{'loss': 1.2803, 'grad_norm': 1.0196603536605835, 'learning_rate': 0.0001281108755582311, 'epoch': 0.41}\n",
      "{'loss': 1.3142, 'grad_norm': 1.5632495880126953, 'learning_rate': 0.0001276947057363927, 'epoch': 0.41}\n",
      "{'loss': 1.3299, 'grad_norm': 1.4914039373397827, 'learning_rate': 0.00012727801575135759, 'epoch': 0.41}\n",
      "{'loss': 1.143, 'grad_norm': 1.2082440853118896, 'learning_rate': 0.0001268608134294156, 'epoch': 0.41}\n",
      "{'loss': 1.1496, 'grad_norm': 1.0442018508911133, 'learning_rate': 0.00012644310660647938, 'epoch': 0.42}\n",
      "{'loss': 1.2373, 'grad_norm': 1.2514781951904297, 'learning_rate': 0.00012602490312793707, 'epoch': 0.42}\n",
      "{'loss': 1.2762, 'grad_norm': 1.7115156650543213, 'learning_rate': 0.000125606210848505, 'epoch': 0.42}\n",
      "{'loss': 1.4192, 'grad_norm': 1.5052337646484375, 'learning_rate': 0.00012518703763208025, 'epoch': 0.42}\n",
      "{'loss': 1.2898, 'grad_norm': 1.3768473863601685, 'learning_rate': 0.00012476739135159286, 'epoch': 0.42}\n",
      "{'loss': 1.3248, 'grad_norm': 1.3599646091461182, 'learning_rate': 0.0001243472798888579, 'epoch': 0.42}\n",
      "{'loss': 1.2987, 'grad_norm': 1.2223049402236938, 'learning_rate': 0.0001239267111344276, 'epoch': 0.42}\n",
      "{'loss': 1.2933, 'grad_norm': 1.3512920141220093, 'learning_rate': 0.00012350569298744303, 'epoch': 0.42}\n",
      "{'loss': 1.3338, 'grad_norm': 1.002423882484436, 'learning_rate': 0.00012308423335548582, 'epoch': 0.43}\n",
      "{'loss': 1.3628, 'grad_norm': 1.1729258298873901, 'learning_rate': 0.0001226623401544295, 'epoch': 0.43}\n",
      "{'loss': 1.2279, 'grad_norm': 1.5254608392715454, 'learning_rate': 0.000122240021308291, 'epoch': 0.43}\n",
      "{'loss': 1.338, 'grad_norm': 1.4531128406524658, 'learning_rate': 0.00012181728474908167, 'epoch': 0.43}\n",
      "{'loss': 1.2918, 'grad_norm': 1.3533110618591309, 'learning_rate': 0.00012139413841665841, 'epoch': 0.43}\n",
      "{'loss': 1.2299, 'grad_norm': 1.1745567321777344, 'learning_rate': 0.00012097059025857451, 'epoch': 0.43}\n",
      "{'loss': 1.2583, 'grad_norm': 1.4906525611877441, 'learning_rate': 0.0001205466482299303, 'epoch': 0.43}\n",
      "{'loss': 1.3509, 'grad_norm': 1.1675647497177124, 'learning_rate': 0.00012012232029322383, 'epoch': 0.44}\n",
      "{'loss': 1.3347, 'grad_norm': 1.3233622312545776, 'learning_rate': 0.00011969761441820138, 'epoch': 0.44}\n",
      "{'loss': 1.2226, 'grad_norm': 1.5458496809005737, 'learning_rate': 0.00011927253858170754, 'epoch': 0.44}\n",
      "{'loss': 1.2959, 'grad_norm': 1.2874290943145752, 'learning_rate': 0.00011884710076753563, 'epoch': 0.44}\n",
      "{'loss': 1.3033, 'grad_norm': 1.5817614793777466, 'learning_rate': 0.00011842130896627766, 'epoch': 0.44}\n",
      "{'loss': 1.3663, 'grad_norm': 1.270403265953064, 'learning_rate': 0.00011799517117517412, 'epoch': 0.44}\n",
      "{'loss': 1.3271, 'grad_norm': 1.3767080307006836, 'learning_rate': 0.00011756869539796405, 'epoch': 0.44}\n",
      "{'loss': 1.2526, 'grad_norm': 1.2680935859680176, 'learning_rate': 0.00011714188964473452, 'epoch': 0.45}\n",
      "{'loss': 1.2365, 'grad_norm': 1.3617249727249146, 'learning_rate': 0.00011671476193177011, 'epoch': 0.45}\n",
      "{'loss': 1.2771, 'grad_norm': 1.618440866470337, 'learning_rate': 0.00011628732028140263, 'epoch': 0.45}\n",
      "{'loss': 1.2567, 'grad_norm': 1.2698765993118286, 'learning_rate': 0.00011585957272186016, 'epoch': 0.45}\n",
      "{'loss': 1.1776, 'grad_norm': 1.126266598701477, 'learning_rate': 0.0001154315272871164, 'epoch': 0.45}\n",
      "{'loss': 1.4126, 'grad_norm': 1.3255314826965332, 'learning_rate': 0.00011500319201673981, 'epoch': 0.45}\n",
      "{'loss': 1.3214, 'grad_norm': 1.2006614208221436, 'learning_rate': 0.00011457457495574251, 'epoch': 0.45}\n",
      "{'loss': 1.143, 'grad_norm': 1.4141640663146973, 'learning_rate': 0.00011414568415442917, 'epoch': 0.46}\n",
      "{'loss': 1.331, 'grad_norm': 1.3934203386306763, 'learning_rate': 0.000113716527668246, 'epoch': 0.46}\n",
      "{'loss': 1.339, 'grad_norm': 1.4164032936096191, 'learning_rate': 0.00011328711355762922, 'epoch': 0.46}\n",
      "{'loss': 1.2712, 'grad_norm': 1.7486497163772583, 'learning_rate': 0.00011285744988785376, 'epoch': 0.46}\n",
      "{'loss': 1.2657, 'grad_norm': 1.2170006036758423, 'learning_rate': 0.00011242754472888183, 'epoch': 0.46}\n",
      "{'loss': 1.2238, 'grad_norm': 1.3492556810379028, 'learning_rate': 0.00011199740615521126, 'epoch': 0.46}\n",
      "{'loss': 1.1406, 'grad_norm': 1.0865050554275513, 'learning_rate': 0.00011156704224572387, 'epoch': 0.46}\n",
      "{'loss': 1.2974, 'grad_norm': 1.1668819189071655, 'learning_rate': 0.00011113646108353386, 'epoch': 0.46}\n",
      "{'loss': 1.3165, 'grad_norm': 1.412925362586975, 'learning_rate': 0.00011070567075583571, 'epoch': 0.47}\n",
      "{'loss': 1.1847, 'grad_norm': 1.3763269186019897, 'learning_rate': 0.0001102746793537526, 'epoch': 0.47}\n",
      "{'loss': 1.1584, 'grad_norm': 1.2734894752502441, 'learning_rate': 0.00010984349497218418, 'epoch': 0.47}\n",
      "{'loss': 1.3614, 'grad_norm': 1.4906712770462036, 'learning_rate': 0.0001094121257096548, 'epoch': 0.47}\n",
      "{'loss': 1.3064, 'grad_norm': 1.7423964738845825, 'learning_rate': 0.00010898057966816109, 'epoch': 0.47}\n",
      "{'loss': 1.2124, 'grad_norm': 1.4615137577056885, 'learning_rate': 0.00010854886495302, 'epoch': 0.47}\n",
      "{'loss': 1.1822, 'grad_norm': 1.3964332342147827, 'learning_rate': 0.00010811698967271664, 'epoch': 0.47}\n",
      "{'loss': 1.1987, 'grad_norm': 1.4888584613800049, 'learning_rate': 0.00010768496193875171, 'epoch': 0.48}\n",
      "{'loss': 1.2129, 'grad_norm': 1.5068453550338745, 'learning_rate': 0.0001072527898654893, 'epoch': 0.48}\n",
      "{'loss': 1.2396, 'grad_norm': 1.5846670866012573, 'learning_rate': 0.00010682048157000461, 'epoch': 0.48}\n",
      "{'loss': 1.142, 'grad_norm': 1.2573195695877075, 'learning_rate': 0.00010638804517193128, 'epoch': 0.48}\n",
      "{'loss': 1.156, 'grad_norm': 1.5411529541015625, 'learning_rate': 0.000105955488793309, 'epoch': 0.48}\n",
      "{'loss': 1.3437, 'grad_norm': 1.6696864366531372, 'learning_rate': 0.00010552282055843097, 'epoch': 0.48}\n",
      "{'loss': 1.2262, 'grad_norm': 1.2272191047668457, 'learning_rate': 0.00010509004859369116, 'epoch': 0.48}\n",
      "{'loss': 1.2374, 'grad_norm': 1.4448848962783813, 'learning_rate': 0.00010465718102743193, 'epoch': 0.49}\n",
      "{'loss': 1.3424, 'grad_norm': 2.045046806335449, 'learning_rate': 0.00010422422598979129, 'epoch': 0.49}\n",
      "{'loss': 1.2439, 'grad_norm': 1.4350740909576416, 'learning_rate': 0.00010379119161254989, 'epoch': 0.49}\n",
      "{'loss': 1.1764, 'grad_norm': 1.251010537147522, 'learning_rate': 0.00010335808602897879, 'epoch': 0.49}\n",
      "{'loss': 1.2257, 'grad_norm': 1.2351173162460327, 'learning_rate': 0.0001029249173736863, 'epoch': 0.49}\n",
      "{'loss': 1.3261, 'grad_norm': 1.3275803327560425, 'learning_rate': 0.00010249169378246542, 'epoch': 0.49}\n",
      "{'loss': 1.2608, 'grad_norm': 1.3690723180770874, 'learning_rate': 0.00010205842339214093, 'epoch': 0.49}\n",
      "{'loss': 1.224, 'grad_norm': 1.1537648439407349, 'learning_rate': 0.00010162511434041664, 'epoch': 0.5}\n",
      "{'loss': 1.2661, 'grad_norm': 1.5517007112503052, 'learning_rate': 0.00010119177476572236, 'epoch': 0.5}\n",
      "{'loss': 1.2125, 'grad_norm': 1.2893924713134766, 'learning_rate': 0.0001007584128070614, 'epoch': 0.5}\n",
      "{'loss': 1.2521, 'grad_norm': 1.5040260553359985, 'learning_rate': 0.0001003250366038573, 'epoch': 0.5}\n",
      "{'loss': 1.3077, 'grad_norm': 1.5507283210754395, 'learning_rate': 9.989165429580124e-05, 'epoch': 0.5}\n",
      "{'loss': 1.2726, 'grad_norm': 1.3176100254058838, 'learning_rate': 9.945827402269902e-05, 'epoch': 0.5}\n",
      "{'loss': 1.267, 'grad_norm': 1.6981033086776733, 'learning_rate': 9.90249039243182e-05, 'epoch': 0.5}\n",
      "{'loss': 1.2399, 'grad_norm': 1.3290934562683105, 'learning_rate': 9.859155214023533e-05, 'epoch': 0.5}\n",
      "{'loss': 1.1508, 'grad_norm': 1.183599591255188, 'learning_rate': 9.81582268096829e-05, 'epoch': 0.51}\n",
      "{'loss': 1.1999, 'grad_norm': 1.4706376791000366, 'learning_rate': 9.772493607139654e-05, 'epoch': 0.51}\n",
      "{'loss': 1.2139, 'grad_norm': 1.2313541173934937, 'learning_rate': 9.729168806346227e-05, 'epoch': 0.51}\n",
      "{'loss': 1.1999, 'grad_norm': 1.3617181777954102, 'learning_rate': 9.685849092316341e-05, 'epoch': 0.51}\n",
      "{'loss': 1.2583, 'grad_norm': 1.6033833026885986, 'learning_rate': 9.642535278682793e-05, 'epoch': 0.51}\n",
      "{'loss': 1.1306, 'grad_norm': 1.5101505517959595, 'learning_rate': 9.599228178967566e-05, 'epoch': 0.51}\n",
      "{'loss': 1.2673, 'grad_norm': 2.358036994934082, 'learning_rate': 9.55592860656653e-05, 'epoch': 0.51}\n",
      "{'loss': 1.2926, 'grad_norm': 1.0434486865997314, 'learning_rate': 9.512637374734186e-05, 'epoch': 0.52}\n",
      "{'loss': 1.307, 'grad_norm': 1.3276078701019287, 'learning_rate': 9.46935529656838e-05, 'epoch': 0.52}\n",
      "{'loss': 1.1698, 'grad_norm': 1.49492347240448, 'learning_rate': 9.426083184995026e-05, 'epoch': 0.52}\n",
      "{'loss': 1.2635, 'grad_norm': 1.6028519868850708, 'learning_rate': 9.382821852752855e-05, 'epoch': 0.52}\n",
      "{'loss': 1.4191, 'grad_norm': 1.6502012014389038, 'learning_rate': 9.339572112378137e-05, 'epoch': 0.52}\n",
      "{'loss': 1.235, 'grad_norm': 1.281492829322815, 'learning_rate': 9.296334776189418e-05, 'epoch': 0.52}\n",
      "{'loss': 1.2448, 'grad_norm': 1.53048837184906, 'learning_rate': 9.253110656272277e-05, 'epoch': 0.52}\n",
      "{'loss': 1.2853, 'grad_norm': 1.4429186582565308, 'learning_rate': 9.20990056446406e-05, 'epoch': 0.53}\n",
      "{'loss': 1.2346, 'grad_norm': 1.423257827758789, 'learning_rate': 9.166705312338631e-05, 'epoch': 0.53}\n",
      "{'loss': 1.3059, 'grad_norm': 1.4485312700271606, 'learning_rate': 9.123525711191141e-05, 'epoch': 0.53}\n",
      "{'loss': 1.1802, 'grad_norm': 1.2966772317886353, 'learning_rate': 9.080362572022782e-05, 'epoch': 0.53}\n",
      "{'loss': 1.332, 'grad_norm': 1.7522646188735962, 'learning_rate': 9.037216705525557e-05, 'epoch': 0.53}\n",
      "{'loss': 1.1429, 'grad_norm': 1.1251683235168457, 'learning_rate': 8.994088922067055e-05, 'epoch': 0.53}\n",
      "{'loss': 1.3137, 'grad_norm': 1.515488624572754, 'learning_rate': 8.950980031675225e-05, 'epoch': 0.53}\n",
      "{'loss': 1.1937, 'grad_norm': 1.0923701524734497, 'learning_rate': 8.907890844023163e-05, 'epoch': 0.54}\n",
      "{'loss': 1.2608, 'grad_norm': 1.159485101699829, 'learning_rate': 8.864822168413913e-05, 'epoch': 0.54}\n",
      "{'loss': 1.1741, 'grad_norm': 1.2244468927383423, 'learning_rate': 8.821774813765255e-05, 'epoch': 0.54}\n",
      "{'loss': 1.2377, 'grad_norm': 1.2957653999328613, 'learning_rate': 8.778749588594528e-05, 'epoch': 0.54}\n",
      "{'loss': 1.1912, 'grad_norm': 1.412629246711731, 'learning_rate': 8.735747301003423e-05, 'epoch': 0.54}\n",
      "{'loss': 1.2685, 'grad_norm': 1.2325329780578613, 'learning_rate': 8.692768758662826e-05, 'epoch': 0.54}\n",
      "{'loss': 1.2284, 'grad_norm': 1.336706280708313, 'learning_rate': 8.649814768797627e-05, 'epoch': 0.54}\n",
      "{'loss': 1.2076, 'grad_norm': 1.1715240478515625, 'learning_rate': 8.606886138171578e-05, 'epoch': 0.54}\n",
      "{'loss': 1.1827, 'grad_norm': 1.4922608137130737, 'learning_rate': 8.563983673072133e-05, 'epoch': 0.55}\n",
      "{'loss': 1.2609, 'grad_norm': 1.2633119821548462, 'learning_rate': 8.521108179295305e-05, 'epoch': 0.55}\n",
      "{'loss': 1.2895, 'grad_norm': 1.2596900463104248, 'learning_rate': 8.478260462130523e-05, 'epoch': 0.55}\n",
      "{'loss': 1.2347, 'grad_norm': 1.2126957178115845, 'learning_rate': 8.435441326345526e-05, 'epoch': 0.55}\n",
      "{'loss': 1.2109, 'grad_norm': 1.230298399925232, 'learning_rate': 8.392651576171224e-05, 'epoch': 0.55}\n",
      "{'loss': 1.1754, 'grad_norm': 1.3679410219192505, 'learning_rate': 8.349892015286608e-05, 'epoch': 0.55}\n",
      "{'loss': 1.3212, 'grad_norm': 1.540368914604187, 'learning_rate': 8.307163446803663e-05, 'epoch': 0.55}\n",
      "{'loss': 1.2186, 'grad_norm': 0.948962926864624, 'learning_rate': 8.264466673252258e-05, 'epoch': 0.56}\n",
      "{'loss': 1.3694, 'grad_norm': 1.553882122039795, 'learning_rate': 8.221802496565101e-05, 'epoch': 0.56}\n",
      "{'loss': 1.2736, 'grad_norm': 1.47023344039917, 'learning_rate': 8.179171718062659e-05, 'epoch': 0.56}\n",
      "{'loss': 1.1998, 'grad_norm': 1.3428791761398315, 'learning_rate': 8.136575138438111e-05, 'epoch': 0.56}\n",
      "{'loss': 1.2828, 'grad_norm': 1.6407333612442017, 'learning_rate': 8.094013557742308e-05, 'epoch': 0.56}\n",
      "{'loss': 1.3213, 'grad_norm': 1.5667197704315186, 'learning_rate': 8.051487775368763e-05, 'epoch': 0.56}\n",
      "{'loss': 1.2596, 'grad_norm': 1.3492014408111572, 'learning_rate': 8.008998590038608e-05, 'epoch': 0.56}\n",
      "{'loss': 1.1953, 'grad_norm': 1.7484192848205566, 'learning_rate': 7.966546799785618e-05, 'epoch': 0.57}\n",
      "{'loss': 1.2102, 'grad_norm': 1.3964779376983643, 'learning_rate': 7.924133201941211e-05, 'epoch': 0.57}\n",
      "{'loss': 1.3215, 'grad_norm': 1.7141717672348022, 'learning_rate': 7.881758593119461e-05, 'epoch': 0.57}\n",
      "{'loss': 1.3328, 'grad_norm': 1.6420190334320068, 'learning_rate': 7.839423769202169e-05, 'epoch': 0.57}\n",
      "{'loss': 1.1392, 'grad_norm': 1.3317656517028809, 'learning_rate': 7.797129525323876e-05, 'epoch': 0.57}\n",
      "{'loss': 1.2319, 'grad_norm': 1.503380537033081, 'learning_rate': 7.754876655856956e-05, 'epoch': 0.57}\n",
      "{'loss': 1.285, 'grad_norm': 1.3893191814422607, 'learning_rate': 7.71266595439669e-05, 'epoch': 0.57}\n",
      "{'loss': 1.264, 'grad_norm': 1.6230955123901367, 'learning_rate': 7.670498213746354e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2676, 'grad_norm': 1.3089618682861328, 'learning_rate': 7.62837422590232e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2445, 'grad_norm': 1.3249895572662354, 'learning_rate': 7.586294782039213e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2486, 'grad_norm': 1.5116220712661743, 'learning_rate': 7.544260672495019e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2112, 'grad_norm': 1.3725529909133911, 'learning_rate': 7.502272686756256e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2954, 'grad_norm': 1.4209532737731934, 'learning_rate': 7.460331613443142e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2265, 'grad_norm': 1.606866478919983, 'learning_rate': 7.41843824029479e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2237, 'grad_norm': 1.335183024406433, 'learning_rate': 7.37659335415439e-05, 'epoch': 0.58}\n",
      "{'loss': 1.2461, 'grad_norm': 1.3597187995910645, 'learning_rate': 7.334797740954465e-05, 'epoch': 0.59}\n",
      "{'loss': 1.2126, 'grad_norm': 1.4468300342559814, 'learning_rate': 7.293052185702078e-05, 'epoch': 0.59}\n",
      "{'loss': 1.228, 'grad_norm': 1.2182003259658813, 'learning_rate': 7.251357472464116e-05, 'epoch': 0.59}\n",
      "{'loss': 1.148, 'grad_norm': 1.6399544477462769, 'learning_rate': 7.209714384352528e-05, 'epoch': 0.59}\n",
      "{'loss': 1.1684, 'grad_norm': 1.3277482986450195, 'learning_rate': 7.168123703509664e-05, 'epoch': 0.59}\n",
      "{'loss': 1.284, 'grad_norm': 1.4691706895828247, 'learning_rate': 7.126586211093534e-05, 'epoch': 0.59}\n",
      "{'loss': 1.1795, 'grad_norm': 1.5249497890472412, 'learning_rate': 7.08510268726317e-05, 'epoch': 0.59}\n",
      "{'loss': 1.1501, 'grad_norm': 1.6634074449539185, 'learning_rate': 7.04367391116397e-05, 'epoch': 0.6}\n",
      "{'loss': 1.1819, 'grad_norm': 1.369296669960022, 'learning_rate': 7.002300660913048e-05, 'epoch': 0.6}\n",
      "{'loss': 1.274, 'grad_norm': 1.8821744918823242, 'learning_rate': 6.960983713584635e-05, 'epoch': 0.6}\n",
      "{'loss': 1.091, 'grad_norm': 1.388890027999878, 'learning_rate': 6.91972384519548e-05, 'epoch': 0.6}\n",
      "{'loss': 1.2615, 'grad_norm': 1.3738934993743896, 'learning_rate': 6.878521830690261e-05, 'epoch': 0.6}\n",
      "{'loss': 1.2283, 'grad_norm': 2.127992630004883, 'learning_rate': 6.837378443927052e-05, 'epoch': 0.6}\n",
      "{'loss': 1.2096, 'grad_norm': 1.2451509237289429, 'learning_rate': 6.79629445766278e-05, 'epoch': 0.6}\n",
      "{'loss': 1.2584, 'grad_norm': 1.3623191118240356, 'learning_rate': 6.755270643538699e-05, 'epoch': 0.61}\n",
      "{'loss': 1.2908, 'grad_norm': 1.332647442817688, 'learning_rate': 6.714307772065916e-05, 'epoch': 0.61}\n",
      "{'loss': 1.2157, 'grad_norm': 1.3122869729995728, 'learning_rate': 6.673406612610912e-05, 'epoch': 0.61}\n",
      "{'loss': 1.2709, 'grad_norm': 1.629981517791748, 'learning_rate': 6.632567933381076e-05, 'epoch': 0.61}\n",
      "{'loss': 1.3129, 'grad_norm': 1.3703945875167847, 'learning_rate': 6.591792501410307e-05, 'epoch': 0.61}\n",
      "{'loss': 1.12, 'grad_norm': 1.383441686630249, 'learning_rate': 6.551081082544584e-05, 'epoch': 0.61}\n",
      "{'loss': 1.191, 'grad_norm': 1.1851004362106323, 'learning_rate': 6.510434441427586e-05, 'epoch': 0.61}\n",
      "{'loss': 1.2417, 'grad_norm': 1.5950552225112915, 'learning_rate': 6.469853341486341e-05, 'epoch': 0.62}\n",
      "{'loss': 1.2918, 'grad_norm': 1.2947497367858887, 'learning_rate': 6.429338544916879e-05, 'epoch': 0.62}\n",
      "{'loss': 1.3151, 'grad_norm': 1.6142842769622803, 'learning_rate': 6.388890812669901e-05, 'epoch': 0.62}\n",
      "{'loss': 1.2468, 'grad_norm': 1.0340561866760254, 'learning_rate': 6.348510904436529e-05, 'epoch': 0.62}\n",
      "{'loss': 1.2103, 'grad_norm': 1.221932291984558, 'learning_rate': 6.308199578633988e-05, 'epoch': 0.62}\n",
      "{'loss': 1.2343, 'grad_norm': 1.4083307981491089, 'learning_rate': 6.267957592391403e-05, 'epoch': 0.62}\n",
      "{'loss': 1.1665, 'grad_norm': 0.9319471716880798, 'learning_rate': 6.227785701535545e-05, 'epoch': 0.62}\n",
      "{'loss': 1.2067, 'grad_norm': 1.5131807327270508, 'learning_rate': 6.187684660576665e-05, 'epoch': 0.62}\n",
      "{'loss': 1.1301, 'grad_norm': 1.3253669738769531, 'learning_rate': 6.14765522269429e-05, 'epoch': 0.63}\n",
      "{'loss': 1.2611, 'grad_norm': 1.3213897943496704, 'learning_rate': 6.107698139723116e-05, 'epoch': 0.63}\n",
      "{'loss': 1.2027, 'grad_norm': 1.3629577159881592, 'learning_rate': 6.0678141621388496e-05, 'epoch': 0.63}\n",
      "{'loss': 1.2356, 'grad_norm': 1.4946835041046143, 'learning_rate': 6.028004039044135e-05, 'epoch': 0.63}\n",
      "{'loss': 1.2087, 'grad_norm': 1.3422534465789795, 'learning_rate': 5.988268518154481e-05, 'epoch': 0.63}\n",
      "{'loss': 1.3116, 'grad_norm': 1.1513078212738037, 'learning_rate': 5.948608345784201e-05, 'epoch': 0.63}\n",
      "{'loss': 1.2012, 'grad_norm': 1.4477455615997314, 'learning_rate': 5.909024266832429e-05, 'epoch': 0.63}\n",
      "{'loss': 1.2488, 'grad_norm': 1.3168015480041504, 'learning_rate': 5.869517024769093e-05, 'epoch': 0.64}\n",
      "{'loss': 1.2724, 'grad_norm': 1.7029080390930176, 'learning_rate': 5.830087361620976e-05, 'epoch': 0.64}\n",
      "{'loss': 1.324, 'grad_norm': 1.2540749311447144, 'learning_rate': 5.7907360179577684e-05, 'epoch': 0.64}\n",
      "{'loss': 1.272, 'grad_norm': 1.49717378616333, 'learning_rate': 5.751463732878159e-05, 'epoch': 0.64}\n",
      "{'loss': 1.0935, 'grad_norm': 1.4868407249450684, 'learning_rate': 5.7122712439959545e-05, 'epoch': 0.64}\n",
      "{'loss': 1.1995, 'grad_norm': 1.3596973419189453, 'learning_rate': 5.673159287426226e-05, 'epoch': 0.64}\n",
      "{'loss': 1.1772, 'grad_norm': 1.3854985237121582, 'learning_rate': 5.6341285977714865e-05, 'epoch': 0.64}\n",
      "{'loss': 1.1994, 'grad_norm': 1.5993330478668213, 'learning_rate': 5.595179908107879e-05, 'epoch': 0.65}\n",
      "{'loss': 1.3027, 'grad_norm': 1.4895358085632324, 'learning_rate': 5.556313949971441e-05, 'epoch': 0.65}\n",
      "{'loss': 1.2092, 'grad_norm': 1.7615424394607544, 'learning_rate': 5.517531453344327e-05, 'epoch': 0.65}\n",
      "{'loss': 1.2357, 'grad_norm': 1.502977967262268, 'learning_rate': 5.4788331466411025e-05, 'epoch': 0.65}\n",
      "{'loss': 1.1534, 'grad_norm': 1.8440996408462524, 'learning_rate': 5.440219756695102e-05, 'epoch': 0.65}\n",
      "{'loss': 1.1717, 'grad_norm': 1.3386503458023071, 'learning_rate': 5.40169200874473e-05, 'epoch': 0.65}\n",
      "{'loss': 1.2231, 'grad_norm': 1.283577799797058, 'learning_rate': 5.363250626419861e-05, 'epoch': 0.65}\n",
      "{'loss': 1.2032, 'grad_norm': 1.4308136701583862, 'learning_rate': 5.3248963317282594e-05, 'epoch': 0.66}\n",
      "{'loss': 1.2074, 'grad_norm': 1.4536982774734497, 'learning_rate': 5.2866298450419934e-05, 'epoch': 0.66}\n",
      "{'loss': 1.2209, 'grad_norm': 1.5178160667419434, 'learning_rate': 5.248451885083912e-05, 'epoch': 0.66}\n",
      "{'loss': 1.2223, 'grad_norm': 1.2850664854049683, 'learning_rate': 5.2103631689141674e-05, 'epoch': 0.66}\n",
      "{'loss': 1.3153, 'grad_norm': 1.644627571105957, 'learning_rate': 5.172364411916724e-05, 'epoch': 0.66}\n",
      "{'loss': 1.3298, 'grad_norm': 1.3930045366287231, 'learning_rate': 5.1344563277859246e-05, 'epoch': 0.66}\n",
      "{'loss': 1.2745, 'grad_norm': 1.2802848815917969, 'learning_rate': 5.096639628513091e-05, 'epoch': 0.66}\n",
      "{'loss': 1.2337, 'grad_norm': 1.0839561223983765, 'learning_rate': 5.058915024373167e-05, 'epoch': 0.66}\n",
      "{'loss': 1.2736, 'grad_norm': 1.4359921216964722, 'learning_rate': 5.021283223911328e-05, 'epoch': 0.67}\n",
      "{'loss': 1.1884, 'grad_norm': 1.2505042552947998, 'learning_rate': 4.983744933929742e-05, 'epoch': 0.67}\n",
      "{'loss': 1.2975, 'grad_norm': 1.156028151512146, 'learning_rate': 4.946300859474239e-05, 'epoch': 0.67}\n",
      "{'loss': 1.2288, 'grad_norm': 1.1617121696472168, 'learning_rate': 4.908951703821091e-05, 'epoch': 0.67}\n",
      "{'loss': 1.2622, 'grad_norm': 1.4707319736480713, 'learning_rate': 4.871698168463802e-05, 'epoch': 0.67}\n",
      "{'loss': 1.2418, 'grad_norm': 1.5337917804718018, 'learning_rate': 4.834540953099941e-05, 'epoch': 0.67}\n",
      "{'loss': 1.2346, 'grad_norm': 1.4270778894424438, 'learning_rate': 4.7974807556179735e-05, 'epoch': 0.67}\n",
      "{'loss': 1.2106, 'grad_norm': 1.7196033000946045, 'learning_rate': 4.760518272084177e-05, 'epoch': 0.68}\n",
      "{'loss': 1.2168, 'grad_norm': 1.178956151008606, 'learning_rate': 4.723654196729572e-05, 'epoch': 0.68}\n",
      "{'loss': 1.1962, 'grad_norm': 1.61875319480896, 'learning_rate': 4.686889221936861e-05, 'epoch': 0.68}\n",
      "{'loss': 1.1653, 'grad_norm': 1.1944432258605957, 'learning_rate': 4.650224038227433e-05, 'epoch': 0.68}\n",
      "{'loss': 1.1264, 'grad_norm': 1.2939950227737427, 'learning_rate': 4.6136593342484134e-05, 'epoch': 0.68}\n",
      "{'loss': 1.2057, 'grad_norm': 1.6363015174865723, 'learning_rate': 4.5771957967596904e-05, 'epoch': 0.68}\n",
      "{'loss': 1.2737, 'grad_norm': 1.4452098608016968, 'learning_rate': 4.540834110621047e-05, 'epoch': 0.68}\n",
      "{'loss': 1.1527, 'grad_norm': 1.2999944686889648, 'learning_rate': 4.504574958779302e-05, 'epoch': 0.69}\n",
      "{'loss': 1.1814, 'grad_norm': 1.0211353302001953, 'learning_rate': 4.468419022255455e-05, 'epoch': 0.69}\n",
      "{'loss': 1.2006, 'grad_norm': 1.7111470699310303, 'learning_rate': 4.432366980131917e-05, 'epoch': 0.69}\n",
      "{'loss': 1.2804, 'grad_norm': 1.3446729183197021, 'learning_rate': 4.396419509539747e-05, 'epoch': 0.69}\n",
      "{'loss': 1.2218, 'grad_norm': 1.1080741882324219, 'learning_rate': 4.3605772856459426e-05, 'epoch': 0.69}\n",
      "{'loss': 1.19, 'grad_norm': 1.7480933666229248, 'learning_rate': 4.324840981640743e-05, 'epoch': 0.69}\n",
      "{'loss': 1.2257, 'grad_norm': 1.318524718284607, 'learning_rate': 4.2892112687250084e-05, 'epoch': 0.69}\n",
      "{'loss': 1.2144, 'grad_norm': 1.2185455560684204, 'learning_rate': 4.253688816097593e-05, 'epoch': 0.7}\n",
      "{'loss': 1.1891, 'grad_norm': 1.4131931066513062, 'learning_rate': 4.218274290942782e-05, 'epoch': 0.7}\n",
      "{'loss': 1.0974, 'grad_norm': 1.181950569152832, 'learning_rate': 4.182968358417765e-05, 'epoch': 0.7}\n",
      "{'loss': 1.1253, 'grad_norm': 1.4717988967895508, 'learning_rate': 4.147771681640139e-05, 'epoch': 0.7}\n",
      "{'loss': 1.2015, 'grad_norm': 1.2252594232559204, 'learning_rate': 4.112684921675456e-05, 'epoch': 0.7}\n",
      "{'loss': 1.1151, 'grad_norm': 1.4138635396957397, 'learning_rate': 4.0777087375247994e-05, 'epoch': 0.7}\n",
      "{'loss': 1.1822, 'grad_norm': 1.2675081491470337, 'learning_rate': 4.042843786112426e-05, 'epoch': 0.7}\n",
      "{'loss': 1.1966, 'grad_norm': 1.315909743309021, 'learning_rate': 4.008090722273402e-05, 'epoch': 0.7}\n",
      "{'loss': 1.2576, 'grad_norm': 1.6741544008255005, 'learning_rate': 3.973450198741321e-05, 'epoch': 0.71}\n",
      "{'loss': 1.1403, 'grad_norm': 1.4651210308074951, 'learning_rate': 3.938922866136038e-05, 'epoch': 0.71}\n",
      "{'loss': 1.3451, 'grad_norm': 1.8920044898986816, 'learning_rate': 3.904509372951452e-05, 'epoch': 0.71}\n",
      "{'loss': 1.261, 'grad_norm': 1.4765352010726929, 'learning_rate': 3.870210365543323e-05, 'epoch': 0.71}\n",
      "{'loss': 1.3485, 'grad_norm': 1.4025681018829346, 'learning_rate': 3.8360264881171405e-05, 'epoch': 0.71}\n",
      "{'loss': 1.1981, 'grad_norm': 1.2597599029541016, 'learning_rate': 3.801958382716011e-05, 'epoch': 0.71}\n",
      "{'loss': 1.1928, 'grad_norm': 1.2694004774093628, 'learning_rate': 3.7680066892086066e-05, 'epoch': 0.71}\n",
      "{'loss': 1.298, 'grad_norm': 1.6633530855178833, 'learning_rate': 3.734172045277148e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2087, 'grad_norm': 1.305045485496521, 'learning_rate': 3.700455086405424e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2674, 'grad_norm': 1.6328039169311523, 'learning_rate': 3.666856445866854e-05, 'epoch': 0.72}\n",
      "{'loss': 1.314, 'grad_norm': 1.4577264785766602, 'learning_rate': 3.6333767547126096e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2224, 'grad_norm': 1.5465196371078491, 'learning_rate': 3.600016641759736e-05, 'epoch': 0.72}\n",
      "{'loss': 1.386, 'grad_norm': 1.5490692853927612, 'learning_rate': 3.566776733579362e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2597, 'grad_norm': 1.5703281164169312, 'learning_rate': 3.533657654484922e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2431, 'grad_norm': 1.681809902191162, 'learning_rate': 3.500660026520437e-05, 'epoch': 0.73}\n",
      "{'loss': 1.2576, 'grad_norm': 1.281400203704834, 'learning_rate': 3.467784469448824e-05, 'epoch': 0.73}\n",
      "{'loss': 1.2517, 'grad_norm': 1.1613593101501465, 'learning_rate': 3.435031600740256e-05, 'epoch': 0.73}\n",
      "{'loss': 1.1607, 'grad_norm': 1.0627250671386719, 'learning_rate': 3.402402035560579e-05, 'epoch': 0.73}\n",
      "{'loss': 1.2953, 'grad_norm': 1.5502103567123413, 'learning_rate': 3.369896386759741e-05, 'epoch': 0.73}\n",
      "{'loss': 1.3223, 'grad_norm': 1.5029277801513672, 'learning_rate': 3.337515264860275e-05, 'epoch': 0.73}\n",
      "{'loss': 1.2682, 'grad_norm': 1.3819899559020996, 'learning_rate': 3.305259278045864e-05, 'epoch': 0.73}\n",
      "{'loss': 1.2495, 'grad_norm': 1.0897738933563232, 'learning_rate': 3.273129032149885e-05, 'epoch': 0.74}\n",
      "{'loss': 1.2431, 'grad_norm': 1.6762737035751343, 'learning_rate': 3.241125130644047e-05, 'epoch': 0.74}\n",
      "{'loss': 1.3079, 'grad_norm': 1.7830555438995361, 'learning_rate': 3.209248174627058e-05, 'epoch': 0.74}\n",
      "{'loss': 1.1655, 'grad_norm': 1.7621855735778809, 'learning_rate': 3.1774987628133265e-05, 'epoch': 0.74}\n",
      "{'loss': 1.1188, 'grad_norm': 1.2843369245529175, 'learning_rate': 3.1458774915217094e-05, 'epoch': 0.74}\n",
      "{'loss': 1.2701, 'grad_norm': 2.387612819671631, 'learning_rate': 3.1143849546643425e-05, 'epoch': 0.74}\n",
      "{'loss': 1.1766, 'grad_norm': 1.2267065048217773, 'learning_rate': 3.083021743735453e-05, 'epoch': 0.74}\n",
      "{'loss': 1.2699, 'grad_norm': 1.3137011528015137, 'learning_rate': 3.0517884478002604e-05, 'epoch': 0.74}\n",
      "{'loss': 1.2956, 'grad_norm': 1.515150785446167, 'learning_rate': 3.020685653483928e-05, 'epoch': 0.75}\n",
      "{'loss': 1.2235, 'grad_norm': 1.2416975498199463, 'learning_rate': 2.989713944960524e-05, 'epoch': 0.75}\n",
      "{'loss': 1.1118, 'grad_norm': 1.1140644550323486, 'learning_rate': 2.9588739039420476e-05, 'epoch': 0.75}\n",
      "{'loss': 1.2149, 'grad_norm': 1.3528611660003662, 'learning_rate': 2.9281661096675338e-05, 'epoch': 0.75}\n",
      "{'loss': 1.2132, 'grad_norm': 1.1113489866256714, 'learning_rate': 2.8975911388921363e-05, 'epoch': 0.75}\n",
      "{'loss': 1.1201, 'grad_norm': 1.2068291902542114, 'learning_rate': 2.8671495658763203e-05, 'epoch': 0.75}\n",
      "{'loss': 1.1299, 'grad_norm': 1.4272381067276, 'learning_rate': 2.836841962375063e-05, 'epoch': 0.75}\n",
      "{'loss': 1.4216, 'grad_norm': 1.7958799600601196, 'learning_rate': 2.8066688976271317e-05, 'epoch': 0.76}\n",
      "{'loss': 1.1889, 'grad_norm': 1.5609767436981201, 'learning_rate': 2.7766309383443633e-05, 'epoch': 0.76}\n",
      "{'loss': 1.2943, 'grad_norm': 1.4292949438095093, 'learning_rate': 2.746728648701047e-05, 'epoch': 0.76}\n",
      "{'loss': 1.1591, 'grad_norm': 1.3400486707687378, 'learning_rate': 2.7169625903233255e-05, 'epoch': 0.76}\n",
      "{'loss': 1.2611, 'grad_norm': 1.381467580795288, 'learning_rate': 2.687333322278629e-05, 'epoch': 0.76}\n",
      "{'loss': 1.2606, 'grad_norm': 1.45950448513031, 'learning_rate': 2.6578414010651888e-05, 'epoch': 0.76}\n",
      "{'loss': 1.2545, 'grad_norm': 1.5076348781585693, 'learning_rate': 2.6284873806015888e-05, 'epoch': 0.76}\n",
      "{'loss': 1.2004, 'grad_norm': 2.162945508956909, 'learning_rate': 2.5992718122163417e-05, 'epoch': 0.77}\n",
      "{'loss': 1.1289, 'grad_norm': 1.2891074419021606, 'learning_rate': 2.5701952446375532e-05, 'epoch': 0.77}\n",
      "{'loss': 1.2009, 'grad_norm': 1.6676456928253174, 'learning_rate': 2.5412582239826177e-05, 'epoch': 0.77}\n",
      "{'loss': 1.2806, 'grad_norm': 1.3416190147399902, 'learning_rate': 2.512461293747942e-05, 'epoch': 0.77}\n",
      "{'loss': 1.155, 'grad_norm': 1.3023438453674316, 'learning_rate': 2.483804994798753e-05, 'epoch': 0.77}\n",
      "{'loss': 1.2192, 'grad_norm': 1.5489493608474731, 'learning_rate': 2.4552898653589353e-05, 'epoch': 0.77}\n",
      "{'loss': 1.1565, 'grad_norm': 1.335799217224121, 'learning_rate': 2.426916441000917e-05, 'epoch': 0.77}\n",
      "{'loss': 1.186, 'grad_norm': 1.2745734453201294, 'learning_rate': 2.3986852546356174e-05, 'epoch': 0.78}\n",
      "{'loss': 1.1999, 'grad_norm': 1.3296260833740234, 'learning_rate': 2.3705968365024423e-05, 'epoch': 0.78}\n",
      "{'loss': 1.2044, 'grad_norm': 0.9932924509048462, 'learning_rate': 2.3426517141593083e-05, 'epoch': 0.78}\n",
      "{'loss': 1.3725, 'grad_norm': 1.5396262407302856, 'learning_rate': 2.3148504124727487e-05, 'epoch': 0.78}\n",
      "{'loss': 1.2044, 'grad_norm': 1.2332746982574463, 'learning_rate': 2.2871934536080498e-05, 'epoch': 0.78}\n",
      "{'loss': 1.3033, 'grad_norm': 1.3992764949798584, 'learning_rate': 2.2596813570194454e-05, 'epoch': 0.78}\n",
      "{'loss': 1.2842, 'grad_norm': 1.821515679359436, 'learning_rate': 2.232314639440357e-05, 'epoch': 0.78}\n",
      "{'loss': 1.1149, 'grad_norm': 1.2016009092330933, 'learning_rate': 2.2050938148736932e-05, 'epoch': 0.78}\n",
      "{'loss': 1.0918, 'grad_norm': 1.5292977094650269, 'learning_rate': 2.178019394582197e-05, 'epoch': 0.79}\n",
      "{'loss': 1.2538, 'grad_norm': 1.3728853464126587, 'learning_rate': 2.1510918870788342e-05, 'epoch': 0.79}\n",
      "{'loss': 1.2269, 'grad_norm': 1.5974750518798828, 'learning_rate': 2.12431179811725e-05, 'epoch': 0.79}\n",
      "{'loss': 1.1846, 'grad_norm': 1.5968356132507324, 'learning_rate': 2.0976796306822677e-05, 'epoch': 0.79}\n",
      "{'loss': 1.1154, 'grad_norm': 1.4877947568893433, 'learning_rate': 2.0711958849804435e-05, 'epoch': 0.79}\n",
      "{'loss': 1.1292, 'grad_norm': 1.4700883626937866, 'learning_rate': 2.0448610584306648e-05, 'epoch': 0.79}\n",
      "{'loss': 1.2191, 'grad_norm': 1.8843415975570679, 'learning_rate': 2.018675645654823e-05, 'epoch': 0.79}\n",
      "{'loss': 1.1408, 'grad_norm': 1.1290099620819092, 'learning_rate': 1.9926401384685047e-05, 'epoch': 0.8}\n",
      "{'loss': 1.1633, 'grad_norm': 1.7062867879867554, 'learning_rate': 1.966755025871765e-05, 'epoch': 0.8}\n",
      "{'loss': 1.1777, 'grad_norm': 1.289702296257019, 'learning_rate': 1.9410207940399405e-05, 'epoch': 0.8}\n",
      "{'loss': 1.1758, 'grad_norm': 1.0862300395965576, 'learning_rate': 1.915437926314523e-05, 'epoch': 0.8}\n",
      "{'loss': 1.2376, 'grad_norm': 1.6855977773666382, 'learning_rate': 1.890006903194067e-05, 'epoch': 0.8}\n",
      "{'loss': 1.1676, 'grad_norm': 1.5941046476364136, 'learning_rate': 1.86472820232519e-05, 'epoch': 0.8}\n",
      "{'loss': 1.2932, 'grad_norm': 1.594818115234375, 'learning_rate': 1.8396022984935757e-05, 'epoch': 0.8}\n",
      "{'loss': 1.1403, 'grad_norm': 1.1645344495773315, 'learning_rate': 1.814629663615063e-05, 'epoch': 0.81}\n",
      "{'loss': 1.2559, 'grad_norm': 1.2731677293777466, 'learning_rate': 1.789810766726797e-05, 'epoch': 0.81}\n",
      "{'loss': 1.1761, 'grad_norm': 1.1566442251205444, 'learning_rate': 1.7651460739784064e-05, 'epoch': 0.81}\n",
      "{'loss': 1.1988, 'grad_norm': 1.6275235414505005, 'learning_rate': 1.7406360486232454e-05, 'epoch': 0.81}\n",
      "{'loss': 1.1479, 'grad_norm': 1.474338412284851, 'learning_rate': 1.716281151009701e-05, 'epoch': 0.81}\n",
      "{'loss': 1.2516, 'grad_norm': 1.7187120914459229, 'learning_rate': 1.6920818385725524e-05, 'epoch': 0.81}\n",
      "{'loss': 1.1657, 'grad_norm': 1.1826337575912476, 'learning_rate': 1.6680385658243526e-05, 'epoch': 0.81}\n",
      "{'loss': 1.1589, 'grad_norm': 1.2202672958374023, 'learning_rate': 1.64415178434693e-05, 'epoch': 0.82}\n",
      "{'loss': 1.2746, 'grad_norm': 1.4806690216064453, 'learning_rate': 1.620421942782876e-05, 'epoch': 0.82}\n",
      "{'loss': 1.1651, 'grad_norm': 1.3459059000015259, 'learning_rate': 1.596849486827131e-05, 'epoch': 0.82}\n",
      "{'loss': 1.2357, 'grad_norm': 1.378186821937561, 'learning_rate': 1.5734348592186098e-05, 'epoch': 0.82}\n",
      "{'loss': 1.1525, 'grad_norm': 1.755654215812683, 'learning_rate': 1.5501784997319002e-05, 'epoch': 0.82}\n",
      "{'loss': 1.2331, 'grad_norm': 1.4989442825317383, 'learning_rate': 1.5270808451689723e-05, 'epoch': 0.82}\n",
      "{'loss': 1.2995, 'grad_norm': 1.0287598371505737, 'learning_rate': 1.5041423293510048e-05, 'epoch': 0.82}\n",
      "{'loss': 1.0873, 'grad_norm': 1.649601697921753, 'learning_rate': 1.481363383110228e-05, 'epoch': 0.82}\n",
      "{'loss': 1.2022, 'grad_norm': 1.4892520904541016, 'learning_rate': 1.4587444342818212e-05, 'epoch': 0.83}\n",
      "{'loss': 1.183, 'grad_norm': 1.579436182975769, 'learning_rate': 1.4362859076958878e-05, 'epoch': 0.83}\n",
      "{'loss': 1.17, 'grad_norm': 1.176864743232727, 'learning_rate': 1.4139882251694814e-05, 'epoch': 0.83}\n",
      "{'loss': 1.1195, 'grad_norm': 1.459470272064209, 'learning_rate': 1.3918518054986607e-05, 'epoch': 0.83}\n",
      "{'loss': 1.1911, 'grad_norm': 1.7184311151504517, 'learning_rate': 1.3698770644506465e-05, 'epoch': 0.83}\n",
      "{'loss': 1.1733, 'grad_norm': 1.4952460527420044, 'learning_rate': 1.3480644147560073e-05, 'epoch': 0.83}\n",
      "{'loss': 1.3138, 'grad_norm': 1.5467431545257568, 'learning_rate': 1.3264142661009005e-05, 'epoch': 0.83}\n",
      "{'loss': 1.2946, 'grad_norm': 1.6618356704711914, 'learning_rate': 1.3049270251193824e-05, 'epoch': 0.84}\n",
      "{'loss': 1.2521, 'grad_norm': 1.1976250410079956, 'learning_rate': 1.2836030953857692e-05, 'epoch': 0.84}\n",
      "{'loss': 1.2537, 'grad_norm': 1.6318857669830322, 'learning_rate': 1.2645515208250091e-05, 'epoch': 0.84}\n",
      "{'loss': 1.1649, 'grad_norm': 1.2951581478118896, 'learning_rate': 1.2435389833179933e-05, 'epoch': 0.84}\n",
      "{'loss': 1.2394, 'grad_norm': 1.9974713325500488, 'learning_rate': 1.2226909100518192e-05, 'epoch': 0.84}\n",
      "{'loss': 1.2187, 'grad_norm': 1.7210017442703247, 'learning_rate': 1.2020076925959233e-05, 'epoch': 0.84}\n",
      "{'loss': 1.1284, 'grad_norm': 1.2847217321395874, 'learning_rate': 1.1814897194234253e-05, 'epoch': 0.84}\n",
      "{'loss': 1.3484, 'grad_norm': 1.54714834690094, 'learning_rate': 1.1611373759038047e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1681, 'grad_norm': 1.3762880563735962, 'learning_rate': 1.1409510442956827e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1653, 'grad_norm': 1.2302827835083008, 'learning_rate': 1.1209311037396442e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1078, 'grad_norm': 1.489715576171875, 'learning_rate': 1.1010779302511021e-05, 'epoch': 0.85}\n",
      "{'loss': 1.379, 'grad_norm': 1.6444190740585327, 'learning_rate': 1.081391896713243e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1932, 'grad_norm': 1.2633204460144043, 'learning_rate': 1.0618733728700302e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1013, 'grad_norm': 1.1695985794067383, 'learning_rate': 1.042522725319245e-05, 'epoch': 0.85}\n",
      "{'loss': 1.2628, 'grad_norm': 1.4008746147155762, 'learning_rate': 1.0233403175056088e-05, 'epoch': 0.86}\n",
      "{'loss': 1.0413, 'grad_norm': 1.4597941637039185, 'learning_rate': 1.0043265097139653e-05, 'epoch': 0.86}\n",
      "{'loss': 1.2083, 'grad_norm': 1.5797971487045288, 'learning_rate': 9.854816590624971e-06, 'epoch': 0.86}\n",
      "{'loss': 1.0655, 'grad_norm': 1.8163042068481445, 'learning_rate': 9.668061194960254e-06, 'epoch': 0.86}\n",
      "{'loss': 1.1114, 'grad_norm': 1.5137195587158203, 'learning_rate': 9.483002417793729e-06, 'epoch': 0.86}\n",
      "{'loss': 1.216, 'grad_norm': 1.5051355361938477, 'learning_rate': 9.299643734907526e-06, 'epoch': 0.86}\n",
      "{'loss': 1.1894, 'grad_norm': 1.4704279899597168, 'learning_rate': 9.117988590152615e-06, 'epoch': 0.86}\n",
      "{'loss': 1.2469, 'grad_norm': 1.333608865737915, 'learning_rate': 8.938040395384029e-06, 'epoch': 0.86}\n",
      "{'loss': 1.3149, 'grad_norm': 1.3822259902954102, 'learning_rate': 8.759802530396766e-06, 'epoch': 0.87}\n",
      "{'loss': 1.1439, 'grad_norm': 1.5079432725906372, 'learning_rate': 8.583278342862355e-06, 'epoch': 0.87}\n",
      "{'loss': 1.2001, 'grad_norm': 1.6468044519424438, 'learning_rate': 8.40847114826594e-06, 'epoch': 0.87}\n",
      "{'loss': 1.19, 'grad_norm': 1.66427743434906, 'learning_rate': 8.235384229844034e-06, 'epoch': 0.87}\n",
      "{'loss': 1.1954, 'grad_norm': 1.434415340423584, 'learning_rate': 8.064020838522857e-06, 'epoch': 0.87}\n",
      "{'loss': 1.2482, 'grad_norm': 1.0053802728652954, 'learning_rate': 7.89438419285724e-06, 'epoch': 0.87}\n",
      "{'loss': 1.183, 'grad_norm': 1.3090094327926636, 'learning_rate': 7.72647747897024e-06, 'epoch': 0.87}\n",
      "{'loss': 1.0495, 'grad_norm': 1.0723286867141724, 'learning_rate': 7.560303850493222e-06, 'epoch': 0.88}\n",
      "{'loss': 1.1583, 'grad_norm': 1.0172913074493408, 'learning_rate': 7.395866428506692e-06, 'epoch': 0.88}\n",
      "{'loss': 1.2191, 'grad_norm': 1.344829797744751, 'learning_rate': 7.2331683014816184e-06, 'epoch': 0.88}\n",
      "{'loss': 1.0962, 'grad_norm': 1.449601173400879, 'learning_rate': 7.072212525221477e-06, 'epoch': 0.88}\n",
      "{'loss': 1.1434, 'grad_norm': 1.8352911472320557, 'learning_rate': 6.913002122804812e-06, 'epoch': 0.88}\n",
      "{'loss': 1.2456, 'grad_norm': 1.3832439184188843, 'learning_rate': 6.755540084528522e-06, 'epoch': 0.88}\n",
      "{'loss': 1.25, 'grad_norm': 1.4041448831558228, 'learning_rate': 6.599829367851606e-06, 'epoch': 0.88}\n",
      "{'loss': 1.1927, 'grad_norm': 1.5003854036331177, 'learning_rate': 6.445872897339689e-06, 'epoch': 0.89}\n",
      "{'loss': 1.2437, 'grad_norm': 1.2886208295822144, 'learning_rate': 6.293673564610047e-06, 'epoch': 0.89}\n",
      "{'loss': 1.2609, 'grad_norm': 1.481074333190918, 'learning_rate': 6.143234228277328e-06, 'epoch': 0.89}\n",
      "{'loss': 1.232, 'grad_norm': 1.5759917497634888, 'learning_rate': 5.994557713899829e-06, 'epoch': 0.89}\n",
      "{'loss': 1.2967, 'grad_norm': 1.3503894805908203, 'learning_rate': 5.847646813926511e-06, 'epoch': 0.89}\n",
      "{'loss': 1.1753, 'grad_norm': 1.5383058786392212, 'learning_rate': 5.702504287644417e-06, 'epoch': 0.89}\n",
      "{'loss': 1.2757, 'grad_norm': 1.5151655673980713, 'learning_rate': 5.559132861126937e-06, 'epoch': 0.89}\n",
      "{'loss': 1.207, 'grad_norm': 1.2055885791778564, 'learning_rate': 5.417535227182591e-06, 'epoch': 0.9}\n",
      "{'loss': 1.2836, 'grad_norm': 1.6466362476348877, 'learning_rate': 5.277714045304449e-06, 'epoch': 0.9}\n",
      "{'loss': 1.1983, 'grad_norm': 1.1975963115692139, 'learning_rate': 5.139671941620172e-06, 'epoch': 0.9}\n",
      "{'loss': 1.1904, 'grad_norm': 1.5122941732406616, 'learning_rate': 5.016957303728543e-06, 'epoch': 0.9}\n",
      "{'loss': 1.22, 'grad_norm': 1.3989213705062866, 'learning_rate': 4.8823025638802476e-06, 'epoch': 0.9}\n",
      "{'loss': 1.2174, 'grad_norm': 1.1723910570144653, 'learning_rate': 4.7494343288618795e-06, 'epoch': 0.9}\n",
      "{'loss': 1.0628, 'grad_norm': 2.3204352855682373, 'learning_rate': 4.618355094210547e-06, 'epoch': 0.9}\n",
      "{'loss': 1.2602, 'grad_norm': 1.2293941974639893, 'learning_rate': 4.48906732186225e-06, 'epoch': 0.9}\n",
      "{'loss': 1.2109, 'grad_norm': 1.3050512075424194, 'learning_rate': 4.361573440105726e-06, 'epoch': 0.91}\n",
      "{'loss': 1.2002, 'grad_norm': 1.4821428060531616, 'learning_rate': 4.235875843536729e-06, 'epoch': 0.91}\n",
      "{'loss': 1.2218, 'grad_norm': 1.3698241710662842, 'learning_rate': 4.111976893013114e-06, 'epoch': 0.91}\n",
      "{'loss': 1.0698, 'grad_norm': 1.798978567123413, 'learning_rate': 3.989878915610479e-06, 'epoch': 0.91}\n",
      "{'loss': 1.1186, 'grad_norm': 1.7930138111114502, 'learning_rate': 3.86958420457848e-06, 'epoch': 0.91}\n",
      "{'loss': 1.218, 'grad_norm': 1.322020173072815, 'learning_rate': 3.7510950192977344e-06, 'epoch': 0.91}\n",
      "{'loss': 1.1009, 'grad_norm': 1.2510663270950317, 'learning_rate': 3.6344135852374173e-06, 'epoch': 0.91}\n",
      "{'loss': 1.1654, 'grad_norm': 1.3379530906677246, 'learning_rate': 3.519542093913397e-06, 'epoch': 0.92}\n",
      "{'loss': 1.2136, 'grad_norm': 1.4060637950897217, 'learning_rate': 3.406482702847147e-06, 'epoch': 0.92}\n",
      "{'loss': 1.1672, 'grad_norm': 1.3859549760818481, 'learning_rate': 3.2952375355251864e-06, 'epoch': 0.92}\n",
      "{'loss': 1.1199, 'grad_norm': 1.260692834854126, 'learning_rate': 3.185808681359215e-06, 'epoch': 0.92}\n",
      "{'loss': 1.2377, 'grad_norm': 1.4608166217803955, 'learning_rate': 3.0781981956468087e-06, 'epoch': 0.92}\n",
      "{'loss': 1.1549, 'grad_norm': 1.4286376237869263, 'learning_rate': 2.9724080995329527e-06, 'epoch': 0.92}\n",
      "{'loss': 1.2673, 'grad_norm': 1.4778741598129272, 'learning_rate': 2.8684403799719152e-06, 'epoch': 0.92}\n",
      "{'loss': 1.2158, 'grad_norm': 1.4595894813537598, 'learning_rate': 2.7662969896900427e-06, 'epoch': 0.93}\n",
      "{'loss': 1.1217, 'grad_norm': 1.0546538829803467, 'learning_rate': 2.665979847149047e-06, 'epoch': 0.93}\n",
      "{'loss': 1.1293, 'grad_norm': 1.3930020332336426, 'learning_rate': 2.567490836509956e-06, 'epoch': 0.93}\n",
      "{'loss': 1.1645, 'grad_norm': 1.624792218208313, 'learning_rate': 2.470831807597751e-06, 'epoch': 0.93}\n",
      "{'loss': 1.2923, 'grad_norm': 1.7849421501159668, 'learning_rate': 2.3760045758666303e-06, 'epoch': 0.93}\n",
      "{'loss': 1.1721, 'grad_norm': 1.2468757629394531, 'learning_rate': 2.28301092236588e-06, 'epoch': 0.93}\n",
      "{'loss': 1.164, 'grad_norm': 1.5330559015274048, 'learning_rate': 2.191852593706456e-06, 'epoch': 0.93}\n",
      "{'loss': 1.361, 'grad_norm': 1.9386920928955078, 'learning_rate': 2.10253130202811e-06, 'epoch': 0.94}\n",
      "{'loss': 1.2251, 'grad_norm': 1.6600165367126465, 'learning_rate': 2.015048724967361e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1274, 'grad_norm': 1.2988510131835938, 'learning_rate': 1.9294065056258526e-06, 'epoch': 0.94}\n",
      "{'loss': 1.2012, 'grad_norm': 1.1991883516311646, 'learning_rate': 1.8456062525395445e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1977, 'grad_norm': 1.3555231094360352, 'learning_rate': 1.7636495396485597e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1956, 'grad_norm': 1.6070377826690674, 'learning_rate': 1.6835379062675071e-06, 'epoch': 0.94}\n",
      "{'loss': 1.2798, 'grad_norm': 1.2863811254501343, 'learning_rate': 1.60527285705665e-06, 'epoch': 0.94}\n",
      "{'loss': 1.1837, 'grad_norm': 1.1098233461380005, 'learning_rate': 1.5288558619936389e-06, 'epoch': 0.94}\n",
      "{'loss': 1.2384, 'grad_norm': 1.357683777809143, 'learning_rate': 1.4542883563458786e-06, 'epoch': 0.95}\n",
      "{'loss': 1.1731, 'grad_norm': 1.2674506902694702, 'learning_rate': 1.3815717406435612e-06, 'epoch': 0.95}\n",
      "{'loss': 1.1457, 'grad_norm': 1.3664445877075195, 'learning_rate': 1.310707380653442e-06, 'epoch': 0.95}\n",
      "{'loss': 1.1794, 'grad_norm': 1.2462000846862793, 'learning_rate': 1.24169660735306e-06, 'epoch': 0.95}\n",
      "{'loss': 1.1498, 'grad_norm': 1.7267075777053833, 'learning_rate': 1.1745407169058253e-06, 'epoch': 0.95}\n",
      "{'loss': 1.2566, 'grad_norm': 1.216381549835205, 'learning_rate': 1.1092409706366823e-06, 'epoch': 0.95}\n",
      "{'loss': 1.1592, 'grad_norm': 1.4320279359817505, 'learning_rate': 1.0457985950083737e-06, 'epoch': 0.95}\n",
      "{'loss': 1.2417, 'grad_norm': 1.572410225868225, 'learning_rate': 9.842147815984027e-07, 'epoch': 0.96}\n",
      "{'loss': 1.1922, 'grad_norm': 1.4357197284698486, 'learning_rate': 9.244906870767178e-07, 'epoch': 0.96}\n",
      "{'loss': 1.3317, 'grad_norm': 1.667754054069519, 'learning_rate': 8.666274331839197e-07, 'epoch': 0.96}\n",
      "{'loss': 1.3138, 'grad_norm': 1.2924468517303467, 'learning_rate': 8.106261067102105e-07, 'epoch': 0.96}\n",
      "{'loss': 1.2042, 'grad_norm': 1.4742482900619507, 'learning_rate': 7.564877594749997e-07, 'epoch': 0.96}\n",
      "{'loss': 1.1764, 'grad_norm': 1.3679875135421753, 'learning_rate': 7.042134083071528e-07, 'epoch': 0.96}\n",
      "{'loss': 1.1286, 'grad_norm': 1.367247462272644, 'learning_rate': 6.538040350258401e-07, 'epoch': 0.96}\n",
      "{'loss': 1.1654, 'grad_norm': 1.601101040840149, 'learning_rate': 6.052605864221627e-07, 'epoch': 0.97}\n",
      "{'loss': 1.2748, 'grad_norm': 1.0842331647872925, 'learning_rate': 5.585839742413446e-07, 'epoch': 0.97}\n",
      "{'loss': 1.178, 'grad_norm': 1.5351357460021973, 'learning_rate': 5.137750751655901e-07, 'epoch': 0.97}\n",
      "{'loss': 1.2035, 'grad_norm': 1.686436653137207, 'learning_rate': 4.708347307976202e-07, 'epoch': 0.97}\n",
      "{'loss': 1.106, 'grad_norm': 1.5234135389328003, 'learning_rate': 4.297637476449179e-07, 'epoch': 0.97}\n",
      "{'loss': 1.2057, 'grad_norm': 1.3019694089889526, 'learning_rate': 3.905628971045183e-07, 'epoch': 0.97}\n",
      "{'loss': 1.2394, 'grad_norm': 1.487366795539856, 'learning_rate': 3.5323291544852034e-07, 'epoch': 0.97}\n",
      "{'loss': 1.1893, 'grad_norm': 1.4304667711257935, 'learning_rate': 3.177745038103308e-07, 'epoch': 0.98}\n",
      "{'loss': 1.3354, 'grad_norm': 1.5563082695007324, 'learning_rate': 2.841883281713864e-07, 'epoch': 0.98}\n",
      "{'loss': 1.1812, 'grad_norm': 1.3922926187515259, 'learning_rate': 2.524750193487524e-07, 'epoch': 0.98}\n",
      "{'loss': 1.1517, 'grad_norm': 1.3537760972976685, 'learning_rate': 2.226351729832099e-07, 'epoch': 0.98}\n",
      "{'loss': 1.2491, 'grad_norm': 1.2281129360198975, 'learning_rate': 1.9466934952807602e-07, 'epoch': 0.98}\n",
      "{'loss': 1.2362, 'grad_norm': 1.671062707901001, 'learning_rate': 1.6857807423870108e-07, 'epoch': 0.98}\n",
      "{'loss': 1.1686, 'grad_norm': 1.291653037071228, 'learning_rate': 1.4436183716256547e-07, 'epoch': 0.98}\n",
      "{'loss': 1.1885, 'grad_norm': 1.3139413595199585, 'learning_rate': 1.2202109313010913e-07, 'epoch': 0.98}\n",
      "{'loss': 1.1314, 'grad_norm': 1.599345088005066, 'learning_rate': 1.0155626174620514e-07, 'epoch': 0.99}\n",
      "{'loss': 1.273, 'grad_norm': 1.528052568435669, 'learning_rate': 8.296772738221048e-08, 'epoch': 0.99}\n",
      "{'loss': 1.1931, 'grad_norm': 1.4058620929718018, 'learning_rate': 6.625583916880507e-08, 'epoch': 0.99}\n",
      "{'loss': 1.3053, 'grad_norm': 1.355987787246704, 'learning_rate': 5.142091098943036e-08, 'epoch': 0.99}\n",
      "{'loss': 1.133, 'grad_norm': 1.3423433303833008, 'learning_rate': 3.8463221474360764e-08, 'epoch': 0.99}\n",
      "{'loss': 1.1181, 'grad_norm': 1.4333810806274414, 'learning_rate': 2.73830139954967e-08, 'epoch': 0.99}\n",
      "{'loss': 1.1919, 'grad_norm': 1.2617837190628052, 'learning_rate': 1.8180496661779345e-08, 'epoch': 0.99}\n",
      "{'loss': 1.3273, 'grad_norm': 1.8536107540130615, 'learning_rate': 1.0855842315316001e-08, 'epoch': 1.0}\n",
      "{'loss': 1.1869, 'grad_norm': 1.505071759223938, 'learning_rate': 5.409188528082698e-09, 'epoch': 1.0}\n",
      "{'loss': 1.2836, 'grad_norm': 1.422034740447998, 'learning_rate': 1.8406375993818004e-09, 'epoch': 1.0}\n",
      "{'loss': 1.2448, 'grad_norm': 1.4475584030151367, 'learning_rate': 1.5025655387690407e-10, 'epoch': 1.0}\n",
      "{'train_runtime': 4542.1319, 'train_samples_per_second': 6.385, 'train_steps_per_second': 1.596, 'train_loss': 1.302021213399953, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7250, training_loss=1.302021213399953, metrics={'train_runtime': 4542.1319, 'train_samples_per_second': 6.385, 'train_steps_per_second': 1.596, 'train_loss': 1.302021213399953, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29041357c3a54392995ecadbe65b1e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM, PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "import os\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, load_in_8bit=False,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True)\n",
    "\n",
    "#model_path = \"/content/tinyllama-colorist-v1/checkpoint-250\"\n",
    "model_path = \"phi2-multi30k-v1/checkpoint-7250\"\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, model_path, from_transformers=True, device_map=\"auto\")\n",
    "\n",
    "model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2560)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (v_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
       "          (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "from time import perf_counter\n",
    "\n",
    "def generate_response(user_input):\n",
    "\n",
    "  prompt = formatted_prompt(user_input)\n",
    "\n",
    "  inputs = tokenizer([prompt], return_tensors=\"pt\")\n",
    "  generation_config = GenerationConfig(penalty_alpha=0.6,do_sample = True,\n",
    "      top_k=5,temperature=0.5,repetition_penalty=1.2,\n",
    "      max_new_tokens=20,pad_token_id=tokenizer.eos_token_id\n",
    "  )\n",
    "  start_time = perf_counter()\n",
    "\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "  outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "  output=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "  #print(output)\n",
    "  output_time = perf_counter() - start_time\n",
    "  #print(f\"Time taken for inference: {round(output_time,2)} seconds\")\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = load_dataset(dataset, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1000/1000 [09:11<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "mydf = pd.DataFrame(columns=['de','en','predicted_de'])\n",
    "for i in tqdm(range(0,len(data_test))):\n",
    "    out=generate_response(user_input=data_test[i]['en'])\n",
    "    out=out.split('Output: ')[1]\n",
    "    #processed_out=re.sub(\"[^A-Za-z0-9., ]\",\"\",out)\n",
    "    mydf=pd.concat([mydf,pd.DataFrame({'de':data_test[i]['de'],'en':data_test[i]['en'],'predicted_de':out},index=[0])],ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.to_csv('phi2-multi30k-v1-EN-GER.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu,  SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "def bleu_score(csv_file):\n",
    "  df_input=pd.read_csv(csv_file)\n",
    "  actual, predicted=[],[]\n",
    "  count=0\n",
    "  for _, r in df_input.iterrows():\n",
    "    #print(r[\"input_de\"])\n",
    "    #print(r[\"output_en\"])\n",
    "    #print(r[\"gt_en\"])\n",
    "    actual.append([r[\"de\"].split()])\n",
    "    predicted.append(r[\"predicted_de\"].split())\n",
    "  #print(actual)\n",
    "  #print(\"===\")\n",
    "  #print(predicted)\n",
    "\n",
    "  bleu_dic={}\n",
    "  bleu_dic['1-grams']=corpus_bleu(actual, predicted, weights=(1.0,0,0,0))\n",
    "  bleu_dic['1-2-grams']=corpus_bleu(actual, predicted, weights=(0.5,0.5,0,0))\n",
    "  bleu_dic['1-3-grams']=corpus_bleu(actual, predicted, weights=(0.3,0.3,0.3,0))\n",
    "  bleu_dic['1-4-grams']=corpus_bleu(actual, predicted, weights=(0.25,0.25,0.25,0.25))\n",
    "  return bleu_dic\n",
    "\n",
    "tinyllama_bleu=bleu_score('phi2-multi30k-v1-EN-GER.csv')\n",
    "\n",
    "plt.bar(x=tinyllama_bleu.keys(), height=tinyllama_bleu.values())\n",
    "plt.title(\"BLEU score for Phi2 initial attempt\")\n",
    "plt.ylim((0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1-grams': 0.3996769098121488,\n",
       " '1-2-grams': 0.3042815081937937,\n",
       " '1-3-grams': 0.26265797579815814,\n",
       " '1-4-grams': 0.17803955265143895}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinyllama_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11717396607183062"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def bleu_sent_score(csv_file):\n",
    "  df_input=pd.read_csv(csv_file)\n",
    "  actual, predicted=[],[]\n",
    "  count=0\n",
    "  scores = []\n",
    "  for _, r in df_input.iterrows():\n",
    "    #print(r[\"input_de\"])\n",
    "    #print(r[\"output_en\"])\n",
    "    #print(r[\"gt_en\"])\n",
    "    actual.append([r[\"de\"].split()])\n",
    "    predicted.append(r[\"predicted_de\"].split())\n",
    "\n",
    "    score = sentence_bleu([r[\"de\"].split()], r[\"predicted_de\"].split())\n",
    "    scores.append(score)\n",
    "\n",
    "\n",
    "\n",
    "  return scores\n",
    "\n",
    "\n",
    "tinyllama_bleu_sent=bleu_sent_score('phi2-multi30k-v1-EN-GER.csv')\n",
    "import numpy as np\n",
    "np.array(tinyllama_bleu_sent).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/hamad.alhammadi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41985870842725537"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('wordnet')\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "df_input = pd.read_csv('phi2-multi30k-v1-EN-GER.csv')\n",
    "df_input = df_input.dropna()\n",
    "actual, predicted = df_input['de'], df_input['predicted_de']\n",
    "scores=[]\n",
    "for reference, hypothesis in zip(actual, predicted):\n",
    "    tokenized_reference = word_tokenize(reference)\n",
    "    tokenized_hypothesis = word_tokenize(hypothesis)\n",
    "    scores.append(meteor_score([tokenized_reference], tokenized_hypothesis))\n",
    "\n",
    "np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1febf2d370a4cdaad12599e80e2961b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.2.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/371e9839ca4e213dde891b066cf3080f75ec7e72/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "comet_metric = load(\"comet\")\n",
    "predicted = df_input['predicted_de'].tolist()\n",
    "actual = df_input['de'].tolist()\n",
    "source = df_input['en'].tolist()\n",
    "results = comet_metric.compute(predictions=predicted, references=actual, sources=source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_score': 0.5962702080011367,\n",
       " 'scores': [0.4412861764431,\n",
       "  0.46389710903167725,\n",
       "  0.3634698688983917,\n",
       "  0.6874225735664368,\n",
       "  0.4601365923881531,\n",
       "  0.4709911048412323,\n",
       "  0.6286498308181763,\n",
       "  0.37637612223625183,\n",
       "  0.8111923336982727,\n",
       "  0.686951220035553,\n",
       "  0.4998358190059662,\n",
       "  0.33985549211502075,\n",
       "  0.668775737285614,\n",
       "  0.4754548966884613,\n",
       "  0.4181016981601715,\n",
       "  0.3706153929233551,\n",
       "  0.6015293598175049,\n",
       "  0.5356162190437317,\n",
       "  0.8355199694633484,\n",
       "  0.36897486448287964,\n",
       "  0.8430176377296448,\n",
       "  0.7646458745002747,\n",
       "  0.7217810153961182,\n",
       "  0.7342789769172668,\n",
       "  0.29266786575317383,\n",
       "  0.7345629334449768,\n",
       "  0.6766157746315002,\n",
       "  0.5289424061775208,\n",
       "  0.5356197953224182,\n",
       "  0.3407313823699951,\n",
       "  0.8292561173439026,\n",
       "  0.6242266297340393,\n",
       "  0.8167948126792908,\n",
       "  0.5593011975288391,\n",
       "  0.9201875329017639,\n",
       "  0.24081498384475708,\n",
       "  0.44100531935691833,\n",
       "  0.3576207160949707,\n",
       "  0.7989457249641418,\n",
       "  0.6665067076683044,\n",
       "  0.28996628522872925,\n",
       "  0.7446200847625732,\n",
       "  0.5943838953971863,\n",
       "  0.5889114737510681,\n",
       "  0.4809873104095459,\n",
       "  0.5371307730674744,\n",
       "  0.7754406929016113,\n",
       "  0.3071664869785309,\n",
       "  0.40542009472846985,\n",
       "  0.9437416791915894,\n",
       "  0.47401347756385803,\n",
       "  0.47713491320610046,\n",
       "  0.3307238519191742,\n",
       "  0.3883573114871979,\n",
       "  0.3787057399749756,\n",
       "  0.6429707407951355,\n",
       "  0.9261323809623718,\n",
       "  0.543739914894104,\n",
       "  0.6691148281097412,\n",
       "  0.39335522055625916,\n",
       "  0.511138379573822,\n",
       "  0.4516036808490753,\n",
       "  0.5457547307014465,\n",
       "  0.5934966206550598,\n",
       "  0.7050917744636536,\n",
       "  0.3369279205799103,\n",
       "  0.7144742012023926,\n",
       "  0.5518105030059814,\n",
       "  0.5968814492225647,\n",
       "  0.8799203634262085,\n",
       "  0.4023799002170563,\n",
       "  0.7466711401939392,\n",
       "  0.41314181685447693,\n",
       "  0.40125375986099243,\n",
       "  0.9286666512489319,\n",
       "  0.4133802354335785,\n",
       "  0.5046679973602295,\n",
       "  0.7310125231742859,\n",
       "  0.5769900679588318,\n",
       "  0.36243611574172974,\n",
       "  0.7966035008430481,\n",
       "  0.3946675658226013,\n",
       "  0.5002869367599487,\n",
       "  0.3663835823535919,\n",
       "  0.2832466661930084,\n",
       "  0.7704209685325623,\n",
       "  0.3455972373485565,\n",
       "  0.36164337396621704,\n",
       "  0.5494629740715027,\n",
       "  0.5737786889076233,\n",
       "  0.7694680094718933,\n",
       "  0.6877502799034119,\n",
       "  0.7722845673561096,\n",
       "  0.6310343146324158,\n",
       "  0.526734471321106,\n",
       "  0.6424862146377563,\n",
       "  0.41242966055870056,\n",
       "  0.4645313322544098,\n",
       "  0.4330886900424957,\n",
       "  0.5921992659568787,\n",
       "  0.7709577679634094,\n",
       "  0.4589567482471466,\n",
       "  0.4160735011100769,\n",
       "  0.4479314088821411,\n",
       "  0.48994970321655273,\n",
       "  0.5347721576690674,\n",
       "  0.8247449994087219,\n",
       "  0.6416101455688477,\n",
       "  0.35617318749427795,\n",
       "  0.307273268699646,\n",
       "  0.6457045674324036,\n",
       "  0.535880982875824,\n",
       "  0.8459689021110535,\n",
       "  0.6094954609870911,\n",
       "  0.43562355637550354,\n",
       "  0.46359068155288696,\n",
       "  0.7913221120834351,\n",
       "  0.4675789773464203,\n",
       "  0.2848535478115082,\n",
       "  0.9672797918319702,\n",
       "  0.5211572051048279,\n",
       "  0.9281586408615112,\n",
       "  0.5927092432975769,\n",
       "  0.6101694107055664,\n",
       "  0.6950375437736511,\n",
       "  0.5243486166000366,\n",
       "  0.8821318745613098,\n",
       "  0.6681999564170837,\n",
       "  0.5839719176292419,\n",
       "  0.4507983326911926,\n",
       "  0.40895137190818787,\n",
       "  0.676283597946167,\n",
       "  0.3778882920742035,\n",
       "  0.5089501738548279,\n",
       "  0.7926777005195618,\n",
       "  0.5533075928688049,\n",
       "  0.37023332715034485,\n",
       "  0.3894769847393036,\n",
       "  0.4399915039539337,\n",
       "  0.6965610980987549,\n",
       "  0.8883289098739624,\n",
       "  0.4981849491596222,\n",
       "  0.8852140307426453,\n",
       "  0.8787427544593811,\n",
       "  0.4913344383239746,\n",
       "  0.4722885191440582,\n",
       "  0.5166113376617432,\n",
       "  0.47196853160858154,\n",
       "  0.548836886882782,\n",
       "  0.4147776663303375,\n",
       "  0.44363024830818176,\n",
       "  0.6933069825172424,\n",
       "  0.6963110566139221,\n",
       "  0.7449051141738892,\n",
       "  0.6085191369056702,\n",
       "  0.6176255941390991,\n",
       "  0.8651112914085388,\n",
       "  0.7190642952919006,\n",
       "  0.6036756038665771,\n",
       "  0.4014480412006378,\n",
       "  0.3772623836994171,\n",
       "  0.9073649048805237,\n",
       "  0.9812904000282288,\n",
       "  0.6994646191596985,\n",
       "  0.8392120003700256,\n",
       "  0.7136659026145935,\n",
       "  0.9526339173316956,\n",
       "  0.429739773273468,\n",
       "  0.9533272385597229,\n",
       "  0.6316432952880859,\n",
       "  0.9007561206817627,\n",
       "  0.37266743183135986,\n",
       "  0.7366260886192322,\n",
       "  0.9007464051246643,\n",
       "  0.7063769102096558,\n",
       "  0.3462432026863098,\n",
       "  0.914337158203125,\n",
       "  0.9235693216323853,\n",
       "  0.2914271056652069,\n",
       "  0.8606827259063721,\n",
       "  0.28917279839515686,\n",
       "  0.43425288796424866,\n",
       "  0.7390994429588318,\n",
       "  0.6189000010490417,\n",
       "  0.6555167436599731,\n",
       "  0.49018731713294983,\n",
       "  0.3382972776889801,\n",
       "  0.6043959856033325,\n",
       "  0.7664631009101868,\n",
       "  0.7622275352478027,\n",
       "  0.7452098727226257,\n",
       "  0.9349549412727356,\n",
       "  0.8693175911903381,\n",
       "  0.5523772239685059,\n",
       "  0.3337096571922302,\n",
       "  0.8380960822105408,\n",
       "  0.6344149708747864,\n",
       "  0.6120418906211853,\n",
       "  0.8121383786201477,\n",
       "  0.5422281622886658,\n",
       "  0.5986935496330261,\n",
       "  0.8410120606422424,\n",
       "  0.6442174911499023,\n",
       "  0.633504331111908,\n",
       "  0.604016125202179,\n",
       "  0.6732576489448547,\n",
       "  0.7616068720817566,\n",
       "  0.5027768611907959,\n",
       "  0.5058326125144958,\n",
       "  0.6835944056510925,\n",
       "  0.883316695690155,\n",
       "  0.6490709185600281,\n",
       "  0.6634363532066345,\n",
       "  0.6221930384635925,\n",
       "  0.4301466941833496,\n",
       "  0.7628857493400574,\n",
       "  0.7875090837478638,\n",
       "  0.43561112880706787,\n",
       "  0.4104757010936737,\n",
       "  0.38972601294517517,\n",
       "  0.4830813705921173,\n",
       "  0.4370633065700531,\n",
       "  0.6358674168586731,\n",
       "  0.3928385078907013,\n",
       "  0.6626386642456055,\n",
       "  0.540199339389801,\n",
       "  0.7561748027801514,\n",
       "  0.4534071385860443,\n",
       "  0.9292191863059998,\n",
       "  0.4609145522117615,\n",
       "  0.5328029990196228,\n",
       "  0.40068620443344116,\n",
       "  0.7936597466468811,\n",
       "  0.32821881771087646,\n",
       "  0.42161551117897034,\n",
       "  0.538050651550293,\n",
       "  0.3691231310367584,\n",
       "  0.5207139849662781,\n",
       "  0.31077682971954346,\n",
       "  0.5965337753295898,\n",
       "  0.5780007243156433,\n",
       "  0.5689825415611267,\n",
       "  0.663157045841217,\n",
       "  0.4360366463661194,\n",
       "  0.8134655952453613,\n",
       "  0.3473109304904938,\n",
       "  0.4309765696525574,\n",
       "  0.5539847612380981,\n",
       "  0.7576364874839783,\n",
       "  0.5552319884300232,\n",
       "  0.8879988789558411,\n",
       "  0.3512629270553589,\n",
       "  0.5242988467216492,\n",
       "  0.5411806702613831,\n",
       "  0.7107126116752625,\n",
       "  0.8356615900993347,\n",
       "  0.8239063620567322,\n",
       "  0.386684775352478,\n",
       "  0.7727119326591492,\n",
       "  0.5667067766189575,\n",
       "  0.6619540452957153,\n",
       "  0.5769066214561462,\n",
       "  0.5311332941055298,\n",
       "  0.7246618866920471,\n",
       "  0.927089273929596,\n",
       "  0.5589991211891174,\n",
       "  0.32149288058280945,\n",
       "  0.5215380787849426,\n",
       "  0.440278559923172,\n",
       "  0.40018486976623535,\n",
       "  0.5395152568817139,\n",
       "  0.6721500754356384,\n",
       "  0.4185892641544342,\n",
       "  0.6028438210487366,\n",
       "  0.8614574074745178,\n",
       "  0.8797632455825806,\n",
       "  0.4703649580478668,\n",
       "  0.7682451605796814,\n",
       "  0.8891980648040771,\n",
       "  0.5614493489265442,\n",
       "  0.9148619174957275,\n",
       "  0.5312936902046204,\n",
       "  0.7121177315711975,\n",
       "  0.4477824866771698,\n",
       "  0.8299592733383179,\n",
       "  0.3575055003166199,\n",
       "  0.498029500246048,\n",
       "  0.8057723641395569,\n",
       "  0.6724801659584045,\n",
       "  0.3687606155872345,\n",
       "  0.7604432106018066,\n",
       "  0.7388654947280884,\n",
       "  0.9059354662895203,\n",
       "  0.8509061932563782,\n",
       "  0.6436994671821594,\n",
       "  0.555853545665741,\n",
       "  0.5713307857513428,\n",
       "  0.9060298204421997,\n",
       "  0.35512033104896545,\n",
       "  0.43350502848625183,\n",
       "  0.44921568036079407,\n",
       "  0.6474031209945679,\n",
       "  0.35169315338134766,\n",
       "  0.42014405131340027,\n",
       "  0.8402828574180603,\n",
       "  0.33178916573524475,\n",
       "  0.3945845067501068,\n",
       "  0.7734564542770386,\n",
       "  0.6407101154327393,\n",
       "  0.5147035717964172,\n",
       "  0.6731131672859192,\n",
       "  0.6595465540885925,\n",
       "  0.46927398443222046,\n",
       "  0.7564448714256287,\n",
       "  0.9127807021141052,\n",
       "  0.36745429039001465,\n",
       "  0.5288605690002441,\n",
       "  0.5622364282608032,\n",
       "  0.6811767816543579,\n",
       "  0.7779942750930786,\n",
       "  0.5951549410820007,\n",
       "  0.39371994137763977,\n",
       "  0.3610111474990845,\n",
       "  0.8821105360984802,\n",
       "  0.7696930766105652,\n",
       "  0.5175668597221375,\n",
       "  0.9280652403831482,\n",
       "  0.7979587316513062,\n",
       "  0.9254477620124817,\n",
       "  0.5819968581199646,\n",
       "  0.6452820897102356,\n",
       "  0.38331910967826843,\n",
       "  0.40981876850128174,\n",
       "  0.34638819098472595,\n",
       "  0.38235023617744446,\n",
       "  0.3275682032108307,\n",
       "  0.5211232304573059,\n",
       "  0.47878649830818176,\n",
       "  0.7392622828483582,\n",
       "  0.496860533952713,\n",
       "  0.5139184594154358,\n",
       "  0.46680667996406555,\n",
       "  0.45194509625434875,\n",
       "  0.7620064616203308,\n",
       "  0.8391194939613342,\n",
       "  0.7265270948410034,\n",
       "  0.8446353673934937,\n",
       "  0.4378088712692261,\n",
       "  0.3545985519886017,\n",
       "  0.3792181611061096,\n",
       "  0.8540001511573792,\n",
       "  0.2945963442325592,\n",
       "  0.6095653772354126,\n",
       "  0.40516766905784607,\n",
       "  0.8899406790733337,\n",
       "  0.42775171995162964,\n",
       "  0.5769931077957153,\n",
       "  0.44097229838371277,\n",
       "  0.9432142972946167,\n",
       "  0.6771570444107056,\n",
       "  0.6309680342674255,\n",
       "  0.6212213039398193,\n",
       "  0.6314677596092224,\n",
       "  0.8192077279090881,\n",
       "  0.6120864748954773,\n",
       "  0.6155825257301331,\n",
       "  0.8995701670646667,\n",
       "  0.46797314286231995,\n",
       "  0.7155964970588684,\n",
       "  0.6090992093086243,\n",
       "  0.43351539969444275,\n",
       "  0.554808497428894,\n",
       "  0.4759667217731476,\n",
       "  0.6023073792457581,\n",
       "  0.5873203873634338,\n",
       "  0.5637226104736328,\n",
       "  0.48830699920654297,\n",
       "  0.3251948654651642,\n",
       "  0.449717253446579,\n",
       "  0.41507822275161743,\n",
       "  0.7667713761329651,\n",
       "  0.5558895468711853,\n",
       "  0.6254247426986694,\n",
       "  0.5321238040924072,\n",
       "  0.441942423582077,\n",
       "  0.5227369070053101,\n",
       "  0.4296707808971405,\n",
       "  0.673706591129303,\n",
       "  0.44274160265922546,\n",
       "  0.8069074153900146,\n",
       "  0.45846983790397644,\n",
       "  0.3614009618759155,\n",
       "  0.5900333523750305,\n",
       "  0.5468641519546509,\n",
       "  0.9583315849304199,\n",
       "  0.2975721061229706,\n",
       "  0.8991147875785828,\n",
       "  0.9454585909843445,\n",
       "  0.900462806224823,\n",
       "  0.6042149662971497,\n",
       "  0.7999797463417053,\n",
       "  0.3236636221408844,\n",
       "  0.7484094500541687,\n",
       "  0.269641250371933,\n",
       "  0.9078546762466431,\n",
       "  0.3669327199459076,\n",
       "  0.39864206314086914,\n",
       "  0.725715696811676,\n",
       "  0.3581477701663971,\n",
       "  0.7162668108940125,\n",
       "  0.3362017571926117,\n",
       "  0.589793860912323,\n",
       "  0.3634137809276581,\n",
       "  0.7276612520217896,\n",
       "  0.8975031971931458,\n",
       "  0.36927199363708496,\n",
       "  0.9265405535697937,\n",
       "  0.5909308791160583,\n",
       "  0.8624266386032104,\n",
       "  0.47991570830345154,\n",
       "  0.3013419210910797,\n",
       "  0.553891122341156,\n",
       "  0.581272542476654,\n",
       "  0.5834580063819885,\n",
       "  0.37004950642585754,\n",
       "  0.2694425880908966,\n",
       "  0.9081674218177795,\n",
       "  0.6192876696586609,\n",
       "  0.4630543291568756,\n",
       "  0.5481587648391724,\n",
       "  0.907358705997467,\n",
       "  0.514912486076355,\n",
       "  0.9397458434104919,\n",
       "  0.7479700446128845,\n",
       "  0.5180925726890564,\n",
       "  0.893800675868988,\n",
       "  0.8755484223365784,\n",
       "  0.4238680303096771,\n",
       "  0.7412391304969788,\n",
       "  0.31278425455093384,\n",
       "  0.7308013439178467,\n",
       "  0.6440622806549072,\n",
       "  0.6227031946182251,\n",
       "  0.8609740734100342,\n",
       "  0.8195523023605347,\n",
       "  0.3385741114616394,\n",
       "  0.4357317388057709,\n",
       "  0.5150734186172485,\n",
       "  0.4718215763568878,\n",
       "  0.6240311861038208,\n",
       "  0.661274790763855,\n",
       "  0.46820399165153503,\n",
       "  0.9092947840690613,\n",
       "  0.6386622786521912,\n",
       "  0.5431219935417175,\n",
       "  0.49948635697364807,\n",
       "  0.5593220591545105,\n",
       "  0.7775687575340271,\n",
       "  0.8328002095222473,\n",
       "  0.45268869400024414,\n",
       "  0.5236151814460754,\n",
       "  0.40135037899017334,\n",
       "  0.7838290333747864,\n",
       "  0.41423675417900085,\n",
       "  0.649583637714386,\n",
       "  0.4324614405632019,\n",
       "  0.8065946698188782,\n",
       "  0.8839021325111389,\n",
       "  0.4566401541233063,\n",
       "  0.5747978687286377,\n",
       "  0.6706045866012573,\n",
       "  0.5368677973747253,\n",
       "  0.7879326939582825,\n",
       "  0.38705742359161377,\n",
       "  0.68812495470047,\n",
       "  0.5002936720848083,\n",
       "  0.4791620075702667,\n",
       "  0.5093175172805786,\n",
       "  0.4212055206298828,\n",
       "  0.5883642435073853,\n",
       "  0.8501371741294861,\n",
       "  0.4224116802215576,\n",
       "  0.49838194251060486,\n",
       "  0.5286926627159119,\n",
       "  0.5274898409843445,\n",
       "  0.5823342204093933,\n",
       "  0.7438763380050659,\n",
       "  0.40680423378944397,\n",
       "  0.9143219590187073,\n",
       "  0.574314296245575,\n",
       "  0.44988688826560974,\n",
       "  0.5293174386024475,\n",
       "  0.8316332697868347,\n",
       "  0.7997143864631653,\n",
       "  0.454042911529541,\n",
       "  0.9622343182563782,\n",
       "  0.9513161182403564,\n",
       "  0.5705087780952454,\n",
       "  0.8793595433235168,\n",
       "  0.47803524136543274,\n",
       "  0.6715466380119324,\n",
       "  0.6599103212356567,\n",
       "  0.8094409704208374,\n",
       "  0.9114465713500977,\n",
       "  0.3690807521343231,\n",
       "  0.3390052318572998,\n",
       "  0.5115492939949036,\n",
       "  0.32907959818840027,\n",
       "  0.9107490181922913,\n",
       "  0.5231664776802063,\n",
       "  0.8283089995384216,\n",
       "  0.7257065773010254,\n",
       "  0.8471397757530212,\n",
       "  0.3955858051776886,\n",
       "  0.7567381858825684,\n",
       "  0.6069417595863342,\n",
       "  0.9110042452812195,\n",
       "  0.6136513352394104,\n",
       "  0.8887141942977905,\n",
       "  0.8674539923667908,\n",
       "  0.6710478067398071,\n",
       "  0.9042497873306274,\n",
       "  0.48012885451316833,\n",
       "  0.44133350253105164,\n",
       "  0.5055579543113708,\n",
       "  0.5976445078849792,\n",
       "  0.5186781287193298,\n",
       "  0.808534562587738,\n",
       "  0.8475784659385681,\n",
       "  0.3239911198616028,\n",
       "  0.7727693915367126,\n",
       "  0.2467121183872223,\n",
       "  0.6492634415626526,\n",
       "  0.471243292093277,\n",
       "  0.7575964331626892,\n",
       "  0.6089987754821777,\n",
       "  0.5812656879425049,\n",
       "  0.8721725940704346,\n",
       "  0.4931347072124481,\n",
       "  0.49969902634620667,\n",
       "  0.41782960295677185,\n",
       "  0.5617555975914001,\n",
       "  0.8270543813705444,\n",
       "  0.5295954942703247,\n",
       "  0.9025939106941223,\n",
       "  0.3856494426727295,\n",
       "  0.3011140525341034,\n",
       "  0.8992811441421509,\n",
       "  0.8786371350288391,\n",
       "  0.7167096734046936,\n",
       "  0.8227943778038025,\n",
       "  0.4626958668231964,\n",
       "  0.7098157405853271,\n",
       "  0.9532203078269958,\n",
       "  0.7671823501586914,\n",
       "  0.5988801121711731,\n",
       "  0.7192379832267761,\n",
       "  0.8917192816734314,\n",
       "  0.540657639503479,\n",
       "  0.3859262764453888,\n",
       "  0.6354290843009949,\n",
       "  0.2767557203769684,\n",
       "  0.7859275937080383,\n",
       "  0.4624466300010681,\n",
       "  0.6694431900978088,\n",
       "  0.5502403378486633,\n",
       "  0.7515724897384644,\n",
       "  0.32024383544921875,\n",
       "  0.6873282194137573,\n",
       "  0.3262712061405182,\n",
       "  0.8674306273460388,\n",
       "  0.7473079562187195,\n",
       "  0.7101690173149109,\n",
       "  0.4907148778438568,\n",
       "  0.5243217349052429,\n",
       "  0.4075169265270233,\n",
       "  0.6338940262794495,\n",
       "  0.6614463329315186,\n",
       "  0.8116016983985901,\n",
       "  0.27404049038887024,\n",
       "  0.7188498377799988,\n",
       "  0.48952168226242065,\n",
       "  0.4190120995044708,\n",
       "  0.5318016409873962,\n",
       "  0.8814742565155029,\n",
       "  0.4193290174007416,\n",
       "  0.6128425002098083,\n",
       "  0.7225257754325867,\n",
       "  0.8235400915145874,\n",
       "  0.6608595252037048,\n",
       "  0.5085463523864746,\n",
       "  0.9503465294837952,\n",
       "  0.9800096154212952,\n",
       "  0.5949118733406067,\n",
       "  0.5478702187538147,\n",
       "  0.3138134777545929,\n",
       "  0.9301570057868958,\n",
       "  0.8247836232185364,\n",
       "  0.5078814625740051,\n",
       "  0.7896099090576172,\n",
       "  0.7730550169944763,\n",
       "  0.3617847263813019,\n",
       "  0.6792818903923035,\n",
       "  0.4178059995174408,\n",
       "  0.4557185173034668,\n",
       "  0.5395139455795288,\n",
       "  0.4432264268398285,\n",
       "  0.6491016745567322,\n",
       "  0.5877030491828918,\n",
       "  0.7770594954490662,\n",
       "  0.485135018825531,\n",
       "  0.46832332015037537,\n",
       "  0.9334609508514404,\n",
       "  0.6242360472679138,\n",
       "  0.6448168158531189,\n",
       "  0.6736436486244202,\n",
       "  0.242079496383667,\n",
       "  0.5066437125205994,\n",
       "  0.4884428083896637,\n",
       "  0.7248222231864929,\n",
       "  0.8820257782936096,\n",
       "  0.5244122743606567,\n",
       "  0.473033607006073,\n",
       "  0.6207770705223083,\n",
       "  0.8391969799995422,\n",
       "  0.5249497294425964,\n",
       "  0.420027494430542,\n",
       "  0.4895365536212921,\n",
       "  0.40214213728904724,\n",
       "  0.8731450438499451,\n",
       "  0.5092539191246033,\n",
       "  0.7233664989471436,\n",
       "  0.5321741104125977,\n",
       "  0.97025066614151,\n",
       "  0.4317612648010254,\n",
       "  0.6737419962882996,\n",
       "  0.7892306447029114,\n",
       "  0.8014494776725769,\n",
       "  0.6354855895042419,\n",
       "  0.28119733929634094,\n",
       "  0.7305306792259216,\n",
       "  0.2839868664741516,\n",
       "  0.611807644367218,\n",
       "  0.3859226405620575,\n",
       "  0.6025522947311401,\n",
       "  0.531261682510376,\n",
       "  0.902553379535675,\n",
       "  0.27993375062942505,\n",
       "  0.898375928401947,\n",
       "  0.9303455352783203,\n",
       "  0.9227669835090637,\n",
       "  0.27714523673057556,\n",
       "  0.3688386082649231,\n",
       "  0.46340104937553406,\n",
       "  0.4801070988178253,\n",
       "  0.5608699917793274,\n",
       "  0.28357264399528503,\n",
       "  0.3803771734237671,\n",
       "  0.5674842000007629,\n",
       "  0.622005045413971,\n",
       "  0.8810918927192688,\n",
       "  0.8074877858161926,\n",
       "  0.6093072295188904,\n",
       "  0.5934776067733765,\n",
       "  0.937062680721283,\n",
       "  0.4241739809513092,\n",
       "  0.80485600233078,\n",
       "  0.5812087059020996,\n",
       "  0.44971707463264465,\n",
       "  0.6315527558326721,\n",
       "  0.8388004899024963,\n",
       "  0.47660911083221436,\n",
       "  0.49744823575019836,\n",
       "  0.4555698335170746,\n",
       "  0.44750016927719116,\n",
       "  0.6909707188606262,\n",
       "  0.6294593214988708,\n",
       "  0.5440728068351746,\n",
       "  0.41576704382896423,\n",
       "  0.44971388578414917,\n",
       "  0.5795509219169617,\n",
       "  0.45204704999923706,\n",
       "  0.4343729317188263,\n",
       "  0.4711579382419586,\n",
       "  0.8568588495254517,\n",
       "  0.28754398226737976,\n",
       "  0.6004584431648254,\n",
       "  0.666325569152832,\n",
       "  0.4495590925216675,\n",
       "  0.822991132736206,\n",
       "  0.590241014957428,\n",
       "  0.2632163166999817,\n",
       "  0.7290247678756714,\n",
       "  0.3937644064426422,\n",
       "  0.3559895157814026,\n",
       "  0.5028725862503052,\n",
       "  0.5118430852890015,\n",
       "  0.870550811290741,\n",
       "  0.45231136679649353,\n",
       "  0.4280836284160614,\n",
       "  0.3339559733867645,\n",
       "  0.5202425122261047,\n",
       "  0.9050813913345337,\n",
       "  0.7838873267173767,\n",
       "  0.529839813709259,\n",
       "  0.6043671369552612,\n",
       "  0.7629707455635071,\n",
       "  0.39544281363487244,\n",
       "  0.4596916437149048,\n",
       "  0.639397919178009,\n",
       "  0.8732767701148987,\n",
       "  0.4158477187156677,\n",
       "  0.940877377986908,\n",
       "  0.7550992369651794,\n",
       "  0.46808820962905884,\n",
       "  0.4874502718448639,\n",
       "  0.7289296388626099,\n",
       "  0.3593941628932953,\n",
       "  0.9001818299293518,\n",
       "  0.8529139757156372,\n",
       "  0.46548786759376526,\n",
       "  0.35868215560913086,\n",
       "  0.6305102705955505,\n",
       "  0.9346561431884766,\n",
       "  0.4885399341583252,\n",
       "  0.6032282114028931,\n",
       "  0.8335720300674438,\n",
       "  0.6979944705963135,\n",
       "  0.679118275642395,\n",
       "  0.4276910424232483,\n",
       "  0.42716678977012634,\n",
       "  0.7586787939071655,\n",
       "  0.3115120828151703,\n",
       "  0.33358457684516907,\n",
       "  0.40347495675086975,\n",
       "  0.6248283982276917,\n",
       "  0.47400960326194763,\n",
       "  0.6472405791282654,\n",
       "  0.6112192869186401,\n",
       "  0.5336279273033142,\n",
       "  0.4588552415370941,\n",
       "  0.4841283857822418,\n",
       "  0.49527207016944885,\n",
       "  0.5620808601379395,\n",
       "  0.3570367097854614,\n",
       "  0.5164675116539001,\n",
       "  0.8191118240356445,\n",
       "  0.6740393042564392,\n",
       "  0.4431360065937042,\n",
       "  0.548962414264679,\n",
       "  0.8625324964523315,\n",
       "  0.575645387172699,\n",
       "  0.6846186518669128,\n",
       "  0.690289318561554,\n",
       "  0.8894945383071899,\n",
       "  0.5205100178718567,\n",
       "  0.6397226452827454,\n",
       "  0.7019771933555603,\n",
       "  0.9727874994277954,\n",
       "  0.4662645757198334,\n",
       "  0.5123119950294495,\n",
       "  0.4339469373226166,\n",
       "  0.39116114377975464,\n",
       "  0.2847845256328583,\n",
       "  0.5470675826072693,\n",
       "  0.32887956500053406,\n",
       "  0.9289588332176208,\n",
       "  0.3613113462924957,\n",
       "  0.39611998200416565,\n",
       "  0.7695942521095276,\n",
       "  0.7900275588035583,\n",
       "  0.6906871199607849,\n",
       "  0.9820669293403625,\n",
       "  0.44608449935913086,\n",
       "  0.5087452530860901,\n",
       "  0.7733929753303528,\n",
       "  0.7293242812156677,\n",
       "  0.6338323950767517,\n",
       "  0.9614982008934021,\n",
       "  0.6881702542304993,\n",
       "  0.5867117047309875,\n",
       "  0.4314425587654114,\n",
       "  0.6937718391418457,\n",
       "  0.6685341000556946,\n",
       "  0.9248408675193787,\n",
       "  0.5233067870140076,\n",
       "  0.8269428610801697,\n",
       "  0.6301426291465759,\n",
       "  0.5967495441436768,\n",
       "  0.355480819940567,\n",
       "  0.8067477941513062,\n",
       "  0.6758950352668762,\n",
       "  0.7732553482055664,\n",
       "  0.4516492784023285,\n",
       "  0.6224671006202698,\n",
       "  0.6823224425315857,\n",
       "  0.755829393863678,\n",
       "  0.6291916370391846,\n",
       "  0.8085598349571228,\n",
       "  0.3825218379497528,\n",
       "  0.874258816242218,\n",
       "  0.39605391025543213,\n",
       "  0.8146426677703857,\n",
       "  0.6782758831977844,\n",
       "  0.36417630314826965,\n",
       "  0.46088707447052,\n",
       "  0.7484084367752075,\n",
       "  0.3656308054924011,\n",
       "  0.5124902129173279,\n",
       "  0.5877610445022583,\n",
       "  0.7197523713111877,\n",
       "  0.6893262267112732,\n",
       "  0.8225749135017395,\n",
       "  0.5794435739517212,\n",
       "  0.6817694306373596,\n",
       "  0.6742717027664185,\n",
       "  0.4281420409679413,\n",
       "  0.6307448744773865,\n",
       "  0.8313210010528564,\n",
       "  0.8911750316619873,\n",
       "  0.7581636905670166,\n",
       "  0.4582255780696869,\n",
       "  0.8309304714202881,\n",
       "  0.3407112658023834,\n",
       "  0.4455919563770294,\n",
       "  0.5384133458137512,\n",
       "  0.7515387535095215,\n",
       "  0.39733147621154785,\n",
       "  0.6226770281791687,\n",
       "  0.5169411301612854,\n",
       "  0.5154237151145935,\n",
       "  0.7865472435951233,\n",
       "  0.7396792769432068,\n",
       "  0.3766074478626251,\n",
       "  0.6387479305267334,\n",
       "  0.33582445979118347,\n",
       "  0.8505867123603821,\n",
       "  0.36803582310676575,\n",
       "  0.6857261061668396,\n",
       "  0.3566111624240875,\n",
       "  0.9145929217338562,\n",
       "  0.487483412027359,\n",
       "  0.7255964875221252,\n",
       "  0.4921218454837799,\n",
       "  0.6321476101875305,\n",
       "  0.5687499046325684,\n",
       "  0.5250211358070374,\n",
       "  0.43261271715164185,\n",
       "  0.6113619208335876,\n",
       "  0.7564720511436462,\n",
       "  0.983849287033081,\n",
       "  0.3551923334598541,\n",
       "  0.6242133378982544,\n",
       "  0.5169767141342163,\n",
       "  0.6328675150871277,\n",
       "  0.7453393936157227,\n",
       "  0.9221875667572021,\n",
       "  0.46987929940223694,\n",
       "  0.8500604033470154,\n",
       "  0.3596780300140381,\n",
       "  0.6164939403533936,\n",
       "  0.9410456418991089,\n",
       "  0.5290308594703674,\n",
       "  0.39113762974739075,\n",
       "  0.6555108428001404,\n",
       "  0.5276049971580505,\n",
       "  0.46637198328971863,\n",
       "  0.527766227722168,\n",
       "  0.5994077920913696,\n",
       "  0.5096973776817322,\n",
       "  0.935752809047699,\n",
       "  0.6047885417938232,\n",
       "  0.823779821395874,\n",
       "  0.3914991319179535,\n",
       "  0.5873119235038757,\n",
       "  0.307876318693161,\n",
       "  0.623645007610321,\n",
       "  0.28872260451316833,\n",
       "  0.4600580632686615,\n",
       "  0.5744245052337646,\n",
       "  0.5198988318443298,\n",
       "  0.27026334404945374,\n",
       "  0.6825266480445862,\n",
       "  0.4243534505367279,\n",
       "  0.6245080232620239,\n",
       "  0.4295186996459961,\n",
       "  0.4048062264919281,\n",
       "  0.3987945020198822,\n",
       "  0.9547747373580933,\n",
       "  0.533492386341095,\n",
       "  0.9105446934700012,\n",
       "  0.428663045167923,\n",
       "  0.31375446915626526,\n",
       "  0.5198550820350647,\n",
       "  0.6234927773475647,\n",
       "  0.6433201432228088,\n",
       "  0.76353919506073,\n",
       "  0.3337545692920685,\n",
       "  0.3695162236690521,\n",
       "  0.2948590815067291,\n",
       "  0.8519765734672546,\n",
       "  0.7137601971626282,\n",
       "  0.7627089619636536,\n",
       "  0.7259962558746338,\n",
       "  0.4474426507949829,\n",
       "  0.26386067271232605,\n",
       "  0.8796975016593933,\n",
       "  0.38748952746391296,\n",
       "  0.7183947563171387,\n",
       "  0.4119848906993866,\n",
       "  0.8163949847221375,\n",
       "  0.41194841265678406,\n",
       "  0.8809211850166321,\n",
       "  0.49769327044487,\n",
       "  0.8847427368164062,\n",
       "  0.653810977935791,\n",
       "  0.8300816416740417,\n",
       "  0.32492396235466003,\n",
       "  0.538851797580719,\n",
       "  0.4095882773399353,\n",
       "  0.540479838848114,\n",
       "  0.5623403191566467,\n",
       "  0.3600538372993469,\n",
       "  0.4437249004840851,\n",
       "  0.3572739362716675,\n",
       "  0.7264050841331482,\n",
       "  0.8489636778831482,\n",
       "  0.48516717553138733,\n",
       "  0.5607094168663025,\n",
       "  0.41019609570503235,\n",
       "  0.5293118357658386,\n",
       "  0.48536649346351624,\n",
       "  0.5570506453514099,\n",
       "  0.6608601212501526,\n",
       "  0.5176622867584229,\n",
       "  0.4105292856693268,\n",
       "  0.5486176013946533,\n",
       "  0.6999471783638,\n",
       "  0.6125038862228394,\n",
       "  0.6160382628440857,\n",
       "  0.6956848502159119,\n",
       "  0.4408629238605499,\n",
       "  0.6972239017486572,\n",
       "  0.7097203135490417,\n",
       "  0.9177422523498535,\n",
       "  0.7367587089538574,\n",
       "  0.48400983214378357,\n",
       "  0.3801470100879669,\n",
       "  0.8967117071151733,\n",
       "  0.4791881740093231,\n",
       "  0.7107699513435364,\n",
       "  0.447944700717926,\n",
       "  0.4830402433872223,\n",
       "  0.35010799765586853,\n",
       "  0.8642048239707947,\n",
       "  0.49995991587638855,\n",
       "  0.4620215594768524,\n",
       "  0.6003555655479431,\n",
       "  0.6480715870857239,\n",
       "  0.3864389955997467,\n",
       "  0.5107514262199402,\n",
       "  0.7258936762809753,\n",
       "  0.5592756867408752,\n",
       "  0.6570681929588318,\n",
       "  0.5611947178840637,\n",
       "  0.2817196547985077,\n",
       "  0.42122694849967957,\n",
       "  0.35810115933418274,\n",
       "  0.4783070981502533,\n",
       "  0.730404794216156,\n",
       "  0.32351475954055786,\n",
       "  0.3736901581287384,\n",
       "  0.6936597228050232,\n",
       "  0.3635677099227905,\n",
       "  0.5828152298927307,\n",
       "  0.6084078550338745,\n",
       "  0.9263840317726135,\n",
       "  0.33844009041786194,\n",
       "  0.4052998721599579,\n",
       "  0.36709925532341003,\n",
       "  0.2693171501159668,\n",
       "  0.5509016513824463,\n",
       "  0.9034383893013,\n",
       "  0.4552004635334015,\n",
       "  0.23383435606956482,\n",
       "  0.4705371558666229,\n",
       "  0.3375962972640991,\n",
       "  0.7082236409187317,\n",
       "  0.9357725977897644,\n",
       "  0.4598495364189148,\n",
       "  0.6250491142272949,\n",
       "  0.534452497959137,\n",
       "  0.3111944794654846,\n",
       "  0.5218216776847839,\n",
       "  0.38438519835472107,\n",
       "  0.4240996837615967,\n",
       "  0.4661291241645813,\n",
       "  0.563568651676178,\n",
       "  0.8946502804756165,\n",
       "  0.9216891527175903]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
